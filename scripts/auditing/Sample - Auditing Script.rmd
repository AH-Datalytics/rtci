---
title: "sample_audit_v1"
output: github_document
---

## Second script to run in a series of three that prepare the RTCI sample for production.
## This script takes the processed data and audits for non-reporting and anomalies.
bring in the sample
```{r}

```

```{r}
```

```{r}


unique_df <- combined_df %>%
  select(city_state) %>%
  distinct()


df1<- as.data.frame(unique(combined_df$city_state))
df2<- as.data.frame(unique(combined_df$city_state))


unique(combined_df$city_state)
unique(combined_df$city_state)

merged_df <- full_join(df1, df2, by = "")

# Print the merged data frame
print("Merged Data Frame:")
print(merged_df)

# Find records without a match in df1
unmatched_in_df1 <- anti_join(df2, df1, by = "city_state")
print("Records in df2 without a match in df1:")
print(unmatched_in_df1)

# Find records without a match in df2
unmatched_in_df2 <- anti_join(df1, df2, by = "city_state")
print("Records in df1 without a match in df2:")
print(unmatched_in_df2)
```


find all months with 0 larcenies
```{r}
theft_zero <- df_mvs_12mo %>%
  filter(Theft == 0)

murd_over_theft <- df_mvs_12mo %>%
  filter(Murder > Theft)

  

##some non-reportes from OH and MA expected
##tracy,ca; beaverton, or the review
```





AUDITING
```{r}
get_column_names_and_formats <- function(df_list) {
  # Extract column names and formats from each data frame
  column_list <- lapply(df_list, function(df) {
    colnames <- colnames(df)
    formats <- sapply(df, class)
    data.frame(ColumnName = colnames, Format = formats, stringsAsFactors = FALSE)
  })
  
  # Combine the column name and format information into a single data frame
  col_df <- do.call(rbind, lapply(seq_along(column_list), function(i) {
    df <- column_list[[i]]
    df$DataFrame <- names(df_list)[i]
    df
  }))
  
  return(col_df)
}

# Function to identify rarely used columns
identify_rare_columns <- function(col_df, threshold = 1) {
  # Count the frequency of each column name
  col_count <- col_df %>%
    group_by(ColumnName) %>%
    summarize(Frequency = n()) %>%
    arrange(Frequency)
  
  # Identify columns used in fewer data frames than the threshold
  rare_columns <- col_count %>%
    filter(Frequency <= threshold)
  
  return(rare_columns)
}

```



```{r}
# Get column names from each data frame
col_df <- get_column_names_and_formats(ldf2)

# Print the breakdown of column names
print(col_df)
```
```{r}
# Identify rarely used columns (e.g., used in 1 or fewer data frames)
rare_columns <- identify_rare_columns(col_df, threshold = 1)

# Print the rarely used columns
print(rare_columns)
```

duplicates?
```{r}
# Function to find unique values for "Agency Name" in a dataframe
get_unique_agencies <- function(df) {
  unique(df$`Agency Name`)
}

# Find unique values for "Agency Name" in all dataframes
unique_agencies_list <- lapply(ldf3, get_unique_agencies)

# Combine all unique values into a single vector
all_unique_agencies <- unlist(unique_agencies_list)

# Find duplicate agency names across all dataframes
duplicate_agencies <- all_unique_agencies[duplicated(all_unique_agencies)]

# View the unique agency names
print("Unique Agency Names Across All Dataframes")
print(unique(all_unique_agencies))

# View the duplicate agency names
print("Duplicate Agency Names Across All Dataframes")
print(duplicate_agencies)
```
what are we kicking when we rowbind?
```{r}
# Function to extract unique values from 'Agency.Name' column in each dataframe
extract_unique_agencies <- function(df_list, column_name) {
  unique_values <- df_list %>%
    map(~ .x %>% pull(.data[[column_name]])) %>%
    unlist() %>%
    unique()
  
  return(unique_values)
}

# Extract unique 'Agency.Name' values from the list of dataframes
unique_agencies <- extract_unique_agencies(ldf3, "Agency Name")

# Create a dataframe with these unique values
df1 <- as.data.frame(unique(unique_agencies))


# Count occurrences of values in the 'name' column for both dataframes
counts_df1 <- as.data.frame(table(df1$name))
counts_df2 <- as.data.frame(table(df2$name))

# Rename columns for clarity
colnames(counts_df1) <- c("name", "count_df1")
colnames(counts_df2) <- c("name", "count_df2")

# Merge the two count dataframes by the 'name' column
comparison <- merge(counts_df1, counts_df2, by = "name", all = TRUE)

# Replace NA values with 0 (if a name is not found in one of the dataframes)
comparison[is.na(comparison)] <- 0

# View the comparison
print("Comparison of Value Counts in 'name' Column Across Two Dataframes")
print(comparison)


# Function to extract unique values from a column and save as a vector
extract_unique_values <- function(df, column_name) {
  unique_values <- df %>% pull(.data[[column_name]]) %>% unique()
  return(unique_values)
}

# Extract unique values from 'Agency.Name' column in both dataframes
unique_values_df1 <- extract_unique_values(df1, "Agency.Name")
unique_values_df2 <- extract_unique_values(combined_df, "Agency Name")

# Compare the unique values between the two vectors
only_in_df1 <- setdiff(unique_values_df1, unique_values_df2)
only_in_df2 <- setdiff(unique_values_df2, unique_values_df1)
in_both <- intersect(unique_values_df1, unique_values_df2)

# Print the comparison results
cat("Unique values only in df1:\n")
print(only_in_df1)
cat("\nUnique values only in df2:\n")
print(only_in_df2)
cat("\nUnique values in both df1 and df2:\n")
print(in_both)

```


## a little auditing
```{r}
# Filter for the specified city_state values
target_cities <- c("Kettering, OH", "Allen, TX", "Hamilton, OH", "Mission, TX", 
                   "Youngstown, OH", "Carrollton, TX", "Rapid City, SD", 
                   "Blue Springs, MO", "Malden, MA", "Bethlehem, PA", 
                   "Sioux Falls, SD")

filtered_data <- df_w_ref %>%
  filter(city_state %in% target_cities)

# Subset to the highest year and highest associated month for each unique city_state
result_data <- filtered_data %>%
  group_by(city_state) %>%
  filter(Year == max(Year)) %>%
  filter(Month == max(Month)) %>%
  ungroup()
```
quick example of error bar creation - just need new min/max values and sd to report and we're good to viz
```{r}
#need ggplot
library(ggplot2)

# Calculate mean and standard error for each month
summary_data <- cdf %>%
  # Create a date column by concatenating Year and Month, and converting to Date object
  mutate(date = as.Date(paste(Year, Month, "01", sep = "-"), format = "%Y-%m-%d")) %>%
  # Group by the date
  group_by(date) %>%
  # Calculate the summary statistics
  summarise(
    mean_crime = mean(Theft, na.rm = TRUE),  # Handle NA values if necessary
    sd_crime = sd(Theft, na.rm = TRUE),      # Handle NA values if necessary
    n = n(),
    sem = sd_crime / sqrt(n)  # Standard Error of the Mean
  )

summary_data_sub <- summary_data %>% filter(year(date) == 2023)

# Assuming `summary_data` is already created as per the previous code

# Plotting with a smoother and enhanced aesthetics
ggplot(summary_data_sub, aes(x = date, y = mean_crime)) +
  # Add a smooth line (LOESS or GAM)
  geom_smooth(method = "loess", se = FALSE, color = "blue", size = 1) +
  
  # Add points to represent mean crime counts
  geom_point(color = "darkred", size = 2) +
  
  # Add error bars with enhanced aesthetics
  geom_errorbar(aes(ymin = mean_crime - sem, ymax = mean_crime + sem), 
                width = 10, color = "darkred", alpha = 0.6) +
  
  # Customize the plot's appearance
  labs(title = "Monthly Crime Counts with Error Bars",
       subtitle = "Including Standard Error Bars and LOESS Smoothing",
       x = "Date",
       y = "Mean Theft Count") +
  theme_minimal(base_size = 15) +  # Minimal theme with larger base text size
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  # Centered title
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotated x-axis labels for better readability
  )

```
let's take a look at all the population-less records
```{r}
pop_missing <- final_data1 %>%
  filter(is.na(Population)) %>%
  distinct(city_state, .keep_all = TRUE)
```


```{r}
df_unique_population <- final_data1 %>%
  group_by(city_state) %>%
  summarise(total_population = sum(Population, na.rm = TRUE))
```
here's where we 
```{r}
# Load necessary library
library(boot)

# Define a function to calculate the mean for each crime type across all agencies by year/month
mean_crime_count_by_agency_month <- function(data, indices) {
  # Subset data based on the bootstrap indices
  d <- data[indices, ]  
  
  # Group by Year and Month, then calculate mean for each crime type
  grouped_means <- d %>%
    group_by(Year, Month) %>%
    summarize(
      mean_assault = mean(`Aggravated Assault`, na.rm = TRUE),
      mean_burglary = mean(Burglary, na.rm = TRUE),
      mean_theft = mean(Theft, na.rm = TRUE),
      mean_murder = mean(Murder, na.rm = TRUE),
      mean_rape = mean(Rape, na.rm = TRUE),
      mean_robbery = mean(Robbery, na.rm = TRUE),
      mean_mtv = mean(`Motor Vehicle Theft`, na.rm = TRUE),
      .groups = 'drop'
    )
  
  # Return the overall mean across all year/month combos for each crime type
  colMeans(grouped_means[, c("mean_assault", "mean_burglary", "mean_theft", "mean_murder",
                              "mean_rape", "mean_robbery", "mean_mtv")], na.rm = TRUE)
}

# Perform bootstrapping
set.seed(123)
boot_results10 <- boot(data = final_data1, 
                     statistic = mean_crime_count_by_agency_month, 
                     R = 10)  # Increase R for more robust results

boot_results50 <- boot(data = final_data1, 
                     statistic = mean_crime_count_by_agency_month, 
                     R = 50)  # Increase R for more robust results

boot_results100 <- boot(data = final_data1, 
                     statistic = mean_crime_count_by_agency_month, 
                     R = 100)  # Increase R for more robust results

boot_results1k <- boot(data = final_data1, 
                     statistic = mean_crime_count_by_agency_month, 
                     R = 1000)  # Increase R for more robust results

# Calculate confidence intervals for each crime type
boot_ci_assault <- boot.ci(boot_results, type = "perc", index = 1)
boot_ci_burglary <- boot.ci(boot_results, type = "perc", index = 2)
boot_ci_theft <- boot.ci(boot_results, type = "perc", index = 3)
boot_ci_murder <- boot.ci(boot_results, type = "perc", index = 4)
boot_ci_rape <- boot.ci(boot_results, type = "perc", index = 5)
boot_ci_robbery <- boot.ci(boot_results, type = "perc", index = 6)
boot_ci_mtv <- boot.ci(boot_results, type = "perc", index = 7)

#10
boot_ci_assault10 <- boot.ci(boot_results10, type = "perc", index = 1)
boot_ci_burglary10 <- boot.ci(boot_results10, type = "perc", index = 2)
boot_ci_theft10 <- boot.ci(boot_results10, type = "perc", index = 3)
boot_ci_murder10 <- boot.ci(boot_results10, type = "perc", index = 4)
boot_ci_rape10 <- boot.ci(boot_results10, type = "perc", index = 5)
boot_ci_robbery10 <- boot.ci(boot_results10, type = "perc", index = 6)
boot_ci_mtv10 <- boot.ci(boot_results10, type = "perc", index = 7)

#50
boot_ci_assault50 <- boot.ci(boot_results50, type = "perc", index = 1)
boot_ci_burglary50 <- boot.ci(boot_results50, type = "perc", index = 2)
boot_ci_theft50 <- boot.ci(boot_results50, type = "perc", index = 3)
boot_ci_murder50 <- boot.ci(boot_results50, type = "perc", index = 4)
boot_ci_rape50 <- boot.ci(boot_results50, type = "perc", index = 5)
boot_ci_robbery50 <- boot.ci(boot_results50, type = "perc", index = 6)
boot_ci_mtv50 <- boot.ci(boot_results50, type = "perc", index = 7)

#100
boot_ci_assault100 <- boot.ci(boot_results100, type = "perc", index = 1)
boot_ci_burglary100 <- boot.ci(boot_results100, type = "perc", index = 2)
boot_ci_theft100 <- boot.ci(boot_results100, type = "perc", index = 3)
boot_ci_murder100 <- boot.ci(boot_results100, type = "perc", index = 4)
boot_ci_rape100 <- boot.ci(boot_results100, type = "perc", index = 5)
boot_ci_robbery100 <- boot.ci(boot_results100, type = "perc", index = 6)
boot_ci_mtv100 <- boot.ci(boot_results100, type = "perc", index = 7)

#1000
boot_ci_assault1k <- boot.ci(boot_results1k, type = "perc", index = 1)
boot_ci_burglary1k <- boot.ci(boot_results1k, type = "perc", index = 2)
boot_ci_theft1k <- boot.ci(boot_results1k, type = "perc", index = 3)
boot_ci_murder1k <- boot.ci(boot_results1k, type = "perc", index = 4)
boot_ci_rape1k <- boot.ci(boot_results1k, type = "perc", index = 5)
boot_ci_robbery1k <- boot.ci(boot_results1k, type = "perc", index = 6)
boot_ci_mtv1k <- boot.ci(boot_results1k, type = "perc", index = 7)
```
10 rep
```{r}
# Calculate the mean and standard deviation for each crime type from the bootstrapped samples
boot_means10 <- colMeans(boot_results10$t)
boot_sds10 <- apply(boot_results10$t, 2, sd)

# Calculate 95% confidence intervals for each crime type
boot_ci10 <- apply(boot_results10$t, 2, function(x) {
  quantile(x, probs = c(0.025, 0.975))
})

# Create a table with the results
crime_summary10 <- data.frame(
  Crime_Type = c("Aggravated Assault", "Burglary", "Theft", "Murder", "Rape", "Robbery", "Motor Vehicle Theft"),
  Mean = boot_means10,
  SD = boot_sds10,
  CI_Lower = boot_ci10[1, ],
  CI_Upper = boot_ci10[2, ]
)
# Display the table
print(crime_summary10)
```
50 rep
```{r}
# Calculate the mean and standard deviation for each crime type from the bootstrapped samples
boot_means50 <- colMeans(boot_results50$t)
boot_sds50 <- apply(boot_results50$t, 2, sd)

# Calculate 95% confidence intervals for each crime type
boot_ci50 <- apply(boot_results50$t, 2, function(x) {
  quantile(x, probs = c(0.025, 0.975))
})

# Create a table with the results
crime_summary50 <- data.frame(
  Crime_Type = c("Aggravated Assault", "Burglary", "Theft", "Murder", "Rape", "Robbery", "Motor Vehicle Theft"),
  Mean = boot_means50,
  SD = boot_sds50,
  CI_Lower = boot_ci50[1, ],
  CI_Upper = boot_ci50[2, ]
)
# Display the table
print(crime_summary50)
```
100 & 1000
```{r}
# Calculate the mean and standard deviation for each crime type from the bootstrapped samples
boot_means100 <- colMeans(boot_results100$t)
boot_sds100 <- apply(boot_results100$t, 2, sd)

# Calculate 95% confidence intervals for each crime type
boot_ci100 <- apply(boot_results100$t, 2, function(x) {
  quantile(x, probs = c(0.025, 0.975))
})

# Create a table with the results
crime_summary100 <- data.frame(
  Crime_Type = c("Aggravated Assault", "Burglary", "Theft", "Murder", "Rape", "Robbery", "Motor Vehicle Theft"),
  Mean = boot_means100,
  SD = boot_sds100,
  CI_Lower = boot_ci100[1, ],
  CI_Upper = boot_ci100[2, ]
)
```

```{r}
# Calculate the mean and standard deviation for each crime type from the bootstrapped samples
boot_means1k <- colMeans(boot_results1k$t)
boot_sds1k <- apply(boot_results1k$t, 2, sd)

# Calculate 95% confidence intervals for each crime type
boot_ci1k <- apply(boot_results1k$t, 2, function(x) {
  quantile(x, probs = c(0.025, 0.975))
})

# Create a table with the results
crime_summary1k <- data.frame(
  Crime_Type = c("Aggravated Assault", "Burglary", "Theft", "Murder", "Rape", "Robbery", "Motor Vehicle Theft"),
  Mean = boot_means1k,
  SD = boot_sds1k,
  CI_Lower = boot_ci1k[1, ],
  CI_Upper = boot_ci1k[2, ]
)
```
write out the summaries
```{r}
#check it out
print(crime_summary10)
print(crime_summary50)
print(crime_summary100)
print(crime_summary1k)

#write out the error bars
write.csv(crime_summary10, "data/error_bars_10rep.csv", row.names = FALSE)
write.csv(crime_summary50, "data/error_bars_50rep.csv", row.names = FALSE)
write.csv(crime_summary100, "data/error_bars_100rep.csv", row.names = FALSE)
write.csv(crime_summary1k, "data/error_bars_1krep.csv", row.names = FALSE)
```
view the error bars
```{r}
# Load the necessary libraries if not already loaded
library(ggplot2)

# Generate the plot with adjustments for better visibility
ggplot(crime_summary1k, aes(x = Crime_Type, y = Mean)) +
  # Add a smooth line (LOESS or GAM)
  geom_smooth(method = "loess", se = FALSE, color = "blue", size = 1) +
  
  # Add points to represent mean crime counts
  geom_point(color = "darkred", size = 2) +
  
  # Add error bars with enhanced aesthetics
  geom_errorbar(aes(ymin = CI_Lower, ymax = CI_Upper), 
                width = 0.2, color = "darkred", alpha = 0.6) +
  
  # Customize the plot's appearance
  labs(title = "Monthly Crime Counts with Error Bars",
       subtitle = "Including Standard Error Bars and LOESS Smoothing",
       x = "Crime Type",
       y = "Mean Offense Count") +
  theme_minimal(base_size = 15) +  # Minimal theme with larger base text size
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),  # Centered title
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)  # Rotated x-axis labels for better readability
  ) +
  # Create a separate plot for each crime type
  facet_wrap(~ Crime_Type, scales = "free_x", ncol = 2) +  # Arrange plots in 2 columns
  theme(strip.text.x = element_text(size = 12, face = "bold"),  # Adjust facet label size
        plot.margin = margin(10, 10, 10, 10))  # Add margins to the plot

```
Date field for vizualizing
```{r}
as.Date(paste(Year, Month, "01", sep = "-"))
```
