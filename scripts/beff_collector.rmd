---
title: "ben/jeff collector"
output: github_document
started: "07-23-2024"
---
read in the data from the ben/jeff folder
```{r}
library(tidyverse)
library(dplyr)
library(readr)
library(stringr)
```
directory path where the arizona files are stored
```{r}
data_dir <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\_Ben and Jeff work"

file_paths <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

crime_types <- c("Agency Name",
                 "Murder", "Rape", "Robbery",
                 "Aggravated Assault", "Burglary", 
                 "Theft", "Motor Vehicle Theft", 
                 "Month", "Year")
```
read everything in, extract the month/year and do the initial processing
```{r}
# Function to read all CSV files in a folder and save them as data frames in a list
read_csvs <- function(folder_path) {
  # List all CSV files in the directory
  file_paths <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)
  
  # Debug: Check if any files are listed
  if (length(file_paths) == 0) {
    stop("No CSV files found in the specified directory.")
  } else {
    message("Processing ", length(file_paths), " files.")
  }
  
  # Function to read a single CSV file
  read_csv_file <- function(file_path) {
    # Debug: Check the file path
    message("Reading file: ", file_path)
    
    # Attempt to read the CSV file
    tryCatch({
      df <- read_csv(file_path, show_col_types = FALSE)
      return(df)
    }, error = function(e) {
      warning("Failed to read: ", file_path, " Error: ", e$message)
      return(NULL)  # Return NULL if the file cannot be read
    })
  }
  
  # Read all CSV files and save them as data frames in a list
  df_list <- lapply(file_paths, read_csv_file)
  
  # Name each element in the list with the corresponding file name (without extension)
  names(df_list) <- tools::file_path_sans_ext(basename(file_paths))
  
  return(df_list)
}

ldf <- read_csvs(data_dir)

# Print the names of the data frames in the list to verify
print(names(ldf))

head(ldf[1])
```
format everything
```{r}
# Define the format_cols function
format_cols <- function(df) {
  # Remove the Arson column
  df <- df[, !(names(df) %in% "Arson")]
  
  # Convert specified columns to character
  char_cols <- c("Agency Name", "State")
  for (col in char_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.character(df[[col]])
    }
  }
  
  # Convert specified columns to numeric
  num_cols <- c("Murder", "Rape", "Robbery", "Aggravated Assault", "Burglary", 
                "Theft", "Motor Vehicle Theft", "Month", "Year")
  for (col in num_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  return(df)
}

ldf1 <- lapply(ldf, format_cols)
head(ldf1[1])
```
```{r}
# Ensure all data frames have the same columns and column types
all_columns <- Reduce(union, lapply(ldf1, names))

# Function to ensure all data frames have the same columns
standardize_columns <- function(df, all_columns) {
  missing_cols <- setdiff(all_columns, names(df))
  for (col in missing_cols) {
    df[[col]] <- NA
  }
  return(df[all_columns])
}

# Apply the standardize_columns function to each dataframe in the list
ldf2 <- lapply(ldf1, standardize_columns, all_columns = all_columns)

#change column names where they don't match - larceny to theft
rename_larceny_to_theft <- function(df) {
  if ("Larceny" %in% names(df)) {
    names(df)[names(df) == "Larceny"] <- "Theft"
  }
  return(df)
}

ldf2 <- lapply(ldf2, rename_larceny_to_theft)
```
still have a few odd column names
```{r}
acceptable_names <- c("Agency Name", "Murder", "Rape", "Robbery", "Aggravated Assault", 
"Burglary", "Theft", "Motor Vehicle Theft", "Year", "Month","State")

# Function to check if a data frame has odd column names
find_odd_columns <- function(df, acceptable_names) {
  # Find columns that are not in the acceptable list
  odd_columns <- setdiff(names(df), acceptable_names)
  return(odd_columns)
}

# Check each data frame for odd column names
odd_columns_list <- lapply(ldf2, find_odd_columns, acceptable_names = acceptable_names)

# Identify data frames with odd column names
dataframes_with_odd_columns <- names(odd_columns_list)[sapply(odd_columns_list, length) > 0]

# Print the odd columns and the corresponding data frames
for (df_name in dataframes_with_odd_columns) {
  cat("Data frame:", df_name, "\n")
  cat("Odd columns:", paste(odd_columns_list[[df_name]], collapse = ", "), "\n\n")
}

# Print the list of data frames with odd column names
print(dataframes_with_odd_columns)
```
combine and check it out
```{r}
combined_df <- do.call(rbind, ldf2)

rownames(combined_df) <- NULL

#drop the extra theft
combined_df <- combined_df[,-12]

head(combined_df)
```
calculate and add nationwide counts
```{r}
nationwide_counts <- combined_df %>%
  group_by(Year, Month) %>%
  summarise(
    Murder= sum(Murder, na.rm = TRUE),
    Rape= sum(Rape, na.rm = TRUE),
    Robbery= sum(Robbery, na.rm = TRUE),
    `Aggravated Assault`= sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary= sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    .groups = 'drop'
  )

# Display the aggregate level dataframe
head(nationwide_counts)
```
add the nationwide counts to the sample once it's working
```{r}
nationwide_counts$`Agency Name` <- "Nationwide Count"

cdf1 <- bind_rows(combined_df, nationwide_counts)
head(cdf1)
```
```{r}
# Function to calculate 12-month cumulative sum 
mvs_12mo <- function(df) {
  df <- df %>%
    arrange(Year, Month) %>%
    group_by(`Agency Name`) %>%
    mutate(across(c(Murder, Burglary, Rape, Robbery, `Aggravated Assault`, `Motor Vehicle Theft`, Theft), 
                  ~ cumsum(.), 
                  .names = "{col}_mvs_12mo")) %>%
    ungroup()
  return(df)
}

# Apply the function to the single dataframe
df_mvs_12mo <- mvs_12mo(cdf1)

# Print the result to verify
head(df_mvs_12mo)
```
write it out!
```{r}
# Specify the folder path
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data"

# Create the full file path
file_path <- file.path(folder_path, "rtci_benjeff_sample.csv")

# Write the data frame to a .csv file
write.csv(df_mvs_12mo, file = file_path, row.names = FALSE)

# Write the data frame to the data folder in Github repo
write.csv(df_mvs_12mo, "data/rtci_benjeff_sample.csv")
```


pull in the tracker 
















AUDITING
```{r}
# Function to get column names from each data frame in the list
get_column_names <- function(df_list) {
  # Extract column names from each data frame
  column_list <- lapply(df_list, colnames)
  
  # Create a data frame with column names and their respective data frame indices
  col_df <- data.frame(
    DataFrame = rep(names(column_list), sapply(column_list, length)),
    ColumnName = unlist(column_list)
  )
  
  return(col_df)
}

# Function to identify rarely used columns
identify_rare_columns <- function(col_df, threshold = 1) {
  # Count the frequency of each column name
  col_count <- col_df %>%
    group_by(ColumnName) %>%
    summarize(Frequency = n()) %>%
    arrange(Frequency)
  
  # Identify columns used in fewer data frames than the threshold
  rare_columns <- col_count %>%
    filter(Frequency <= threshold)
  
  return(rare_columns)
}

```



```{r}
# Get column names from each data frame
col_df <- get_column_names(ldf)

# Print the breakdown of column names
print(col_df)
```
```{r}
# Identify rarely used columns (e.g., used in 1 or fewer data frames)
rare_columns <- identify_rare_columns(col_df, threshold = 1)

# Print the rarely used columns
print(rare_columns)
```