---
title: "county exploration"
output: github_document
---
december 2024 sample prepare
```{r}
#read in the data
library(tidyverse)
library(magrittr)
library(dplyr)
library(readr)
library(stringr)
library(zoo)
library(ggplot2)
library(here)
library(readxl)
library(tools)
```
directory path where the data files are stored
```{r}
#directory path where the data files are stored
# Dynamically locate OneDrive directory
onedrive_mac <- "~/Library/CloudStorage/OneDrive-ahdatalytics.com"
onedrive_win <- file.path("C:", "OneDrive", "OneDrive - ahdatalytics.com")

if (dir.exists(onedrive_mac)) {
  onedrive_dir <- normalizePath(onedrive_mac)
} else if (dir.exists(onedrive_win)) {
  onedrive_dir <- normalizePath(onedrive_win)
} else {
  stop("OneDrive directory not found.")
}

# Define the raw data directory with the correct relative path from OneDrive
data_dir <- file.path(
  onedrive_dir,
  "Clients",
  "Real Time Crime Index",
  "Open Source Data",
  "_Ben and Jeff work",
  "Counties"
)

# Check the full path to ensure it's correct
print(data_dir)

# Get a list of all CSV file paths within the directory
file_paths <- list.files(data_dir, pattern = "\\.xlsx$", full.names = TRUE)

# Check the files
head(file_paths)
```
read in counties files
```{r}
# Function to read the first sheet from all Excel files in a folder and save them as data frames in a list
read_excels <- function(folder_path) {
  # List all Excel files in the directory
  file_paths <- list.files(folder_path, pattern = "\\.xlsx$", full.names = TRUE)
  
  # Debug: Check if any files are listed
  if (length(file_paths) == 0) {
    stop("No Excel files found in the specified directory.")
  } else {
    message("Processing ", length(file_paths), " files.")
  }
  
  # Function to read the first sheet of a single Excel file
  read_excel_file <- function(file_path) {
    # Debug: Check the file path
    message("Reading file: ", file_path)
    
    # Attempt to read the first sheet of the Excel file
    tryCatch({
      df <- read_excel(file_path, sheet = 1)
      return(df)
    }, error = function(e) {
      warning("Failed to read: ", file_path, " Error: ", e$message)
      return(NULL)  # Return NULL if the file cannot be read
    })
  }
  
  # Read all Excel files and save them as data frames in a list
  df_list <- lapply(file_paths, read_excel_file)
  
  # Name each element in the list with the corresponding file name (without extension)
  names(df_list) <- file_path_sans_ext(basename(file_paths))
  
  return(df_list)
}

# Read Excel files from the directory
county_ldf <- read_excels(data_dir)

# View the first data frame in the list
head(county_ldf[[1]])
```
let's get the unique number of agencies at the beginning
```{r}
# Function to get the count of unique 'Agency Name' in each csv
get_unique_agency_count <- function(df) {
  length(unique(df$`Agency Name`))
}

# Apply the function to each dataframe in the list and store the results
unique_agency_counts <- map(county_ldf, get_unique_agency_count)
total_agency_raw <- sum(unlist(unique_agency_counts))
head(total_agency_raw)
##393 for November 2024
```
format everything
```{r}
# Define the format_cols function
format_cols <- function(df) {
  # Remove the Arson column
  df <- df[, !(names(df) %in% "Arson")]
  
  # Convert specified columns to character
  char_cols <- c("Agency Name", "State")
  for (col in char_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.character(df[[col]])
    }
  }
  
  # Convert specified columns to numeric
  num_cols <- c("Murder", "Rape", "Robbery", "Aggravated Assault", "Burglary",
                "Theft", "Motor Vehicle Theft", "Month", "Year")
  for (col in num_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  return(df)
}

# Apply to all dataframes in the list
county_ldf1 <- lapply(county_ldf, format_cols)

# What do we see
head(county_ldf1[1])
```
post-formatting check we still have the same number of agencies before binding
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts1 <- map(county_ldf1, get_unique_agency_count)

# what is the sum of all those raw counts
total_agency_raw1 <- sum(unlist(unique_agency_counts1))

# Print the results
head(total_agency_raw1)
#matches up - November 2024
```
next...standardize the columns across all dataframes in the list
```{r}
# Ensure all data frames have the same columns and column types
all_columns <- Reduce(union, lapply(county_ldf1, names))

# Function to ensure all data frames have the same columns
standardize_columns <- function(df, all_columns) {
  missing_cols <- setdiff(all_columns, names(df))
  for (col in missing_cols) {
    df[[col]] <- NA
  }
  return(df[all_columns])
}

# Apply the standardize_columns function to each dataframe in the list
county_ldf2 <- lapply(county_ldf1, standardize_columns, all_columns = all_columns)

#make sure we're good
head(county_ldf2[1])
```
another check that after formatting we still have the same number of agencies before binding
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts2 <- map(county_ldf2, get_unique_agency_count)

# what is the sum of all those raw counts
total_agency_raw2 <- sum(unlist(unique_agency_counts2))

# Print the results
head(total_agency_raw2)
#393 - matches up November
```
get rid of the extra blank lgl formatted columns that plague our data
```{r}
acceptable_names <- c("Agency Name", "Murder", "Rape", "Robbery", "Aggravated Assault", 
"Burglary", "Theft", "Motor Vehicle Theft", "Year", "Month", "State")

#remove any columns not in the above list
county_ldf3 <- lapply(county_ldf2, function(df) {
  df[, (names(df) %in% acceptable_names)]
})

#take a look
head(county_ldf3[1])
```
one last check that after formatting & standardizing we still have the same number of agencies before binding
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts3 <- map(county_ldf3, get_unique_agency_count)

# what is the sum of all those raw counts
total_agency_raw3 <- sum(unlist(unique_agency_counts3))

# check it out
print(total_agency_raw3)
#393 matches - November
```
stop the process if there is a dataframe that does not have each of the acceptable names and print
```{r}
# Initialize an empty list to store the names of dataframes with missing columns
df_missing_columns <- list()

# Function to check if a dataframe has all the acceptable column names
check_columns <- function(df, df_name, acceptable_names) {
  missing_cols <- setdiff(acceptable_names, colnames(df))
  if (length(missing_cols) > 0) {
    df_missing_columns[[df_name]] <- missing_cols  # Add to the list if columns are missing
  }
}

# Loop through the dataframes and check each one
for (df_name in names(county_ldf3)) {
  check_columns(county_ldf3[[df_name]], df_name, acceptable_names)
}

# Review the dataframes that are missing columns
if (length(df_missing_columns) > 0) {
  print("The following dataframes are missing columns:")
  print(df_missing_columns)
} else {
  print("All dataframes have the required columns.")
}
```
combine and check it out
```{r}
# combine everything together 
county_combined_df <- bind_rows(county_ldf3)

# Step 2: Reset row names
rownames(county_combined_df) <- NULL

#select out acceptable columns and take a look just to make sure
county_combined_df <- county_combined_df %>% select(acceptable_names)
head(county_combined_df)
#looking good.
```
city state column for getting unique number of agencies
```{r}
#create the city_state column here for a unique ID
county_combined_df <- county_combined_df %>% mutate(city_state = paste(`Agency Name`, State, sep = ", "))

#check that unique agencies checks matches city_state check
length(unique(county_combined_df$city_state))
#393 all set
length(unique(county_combined_df$`Agency Name`))
#380 - springfields galore!
```
check out city_state by state for a quick numbers check
```{r}
cty_agency_by_state <- county_combined_df %>%
  group_by(State) %>%
  summarise(unique_city_state_count = n_distinct(city_state))

cty_na_city_states <- county_combined_df %>%
  filter(is.na(State)) %>%
  select(city_state)

# View the result
print(cty_na_city_states)
```
final count issues ID'ed before sent along to be merged with base dataset
```{r}
# Ensure NA's are explicitly marked as NA in designated columns
counties_cdf <- county_combined_df %>%
  mutate(
    Murder = ifelse(is.na(Murder), NA, Murder),
    Rape = ifelse(is.na(Rape), NA, Rape),
    Robbery = ifelse(is.na(Robbery), NA, Robbery),
    `Aggravated Assault`= ifelse(is.na(`Aggravated Assault`), NA, `Aggravated Assault`),
    Burglary = ifelse(is.na(Burglary), NA, Burglary),
    Theft = ifelse(is.na(Theft), NA, Theft),
    `Motor Vehicle Theft` = ifelse(is.na(`Motor Vehicle Theft`),NA, `Motor Vehicle Theft`),
    Agency_Type = "County"
  )
```
run the above 
```{r}
# Perform the merge
counties_cdf_test <- merge(counties_cdf, ref_df2, by = c("city_state", "Agency_Type"), all.x = TRUE)

# Select one record per unique city_state where region_name.x is NA
unique_na_region <- counties_cdf_test %>%
  filter(is.na(region_name.x)) %>%
  distinct(city_state, .keep_all = TRUE)

# Display the result
print(unique_na_region)
```