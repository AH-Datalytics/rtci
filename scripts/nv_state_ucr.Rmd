---
title: "nevada ucr processing"
output: pdf_document
date: "2024-04-19"
updated: "2024-06-10"
updated: "2024-06-28"
updated: "2024-07-03"
---
```{r}
library(tidyverse)
library(stringr)
```
directory location
```{r}
data_dir <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Nevada\\State UCR"
```
read everything in, extract the month/year and do the initial processing
```{r}
# List all CSV files in the directory
file_paths <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

# Debug: Check if any files are listed
if (length(file_paths) == 0) {
  stop("No CSV files found in the specified directory.")
} else {
  message("Processing ", length(file_paths), " files.")
}

# Function to read a CSV and extract date parts
process_csv <- function(file_path) {
  # Debug: Check the file path
  message("Reading file: ", file_path)
  
  # Attempt to read the CSV file
  tryCatch({
    df <- read_csv(file_path, show_col_types = FALSE)
  }, error = function(e) {
    warning("Failed to read: ", file_path, " Error: ", e$message)
    return(NULL)  # Return NULL if the file cannot be read
  })

  # Extract the first 7 characters from the filename (assumes 'YYYY-MM' format)
  filename <- basename(file_path)
  date_part <- substr(filename, 1, 7)

  # Parse year and month from the date_part
  year <- as.integer(substr(date_part, 1, 4))
  month <- as.integer(substr(date_part, 6, 7))

  # Add year and month as columns
  if (!is.na(year) && !is.na(month)) {
    df <- df %>%
      mutate(Year = year, Month = month)
  } else {
    warning("Date parsing failed for: ", filename)
  }

  return(df)
}

# Apply the function to each file path and store dataframes in a list
ldf <- setNames(lapply(file_paths, process_csv), basename(file_paths))
```
what does the top look like
```{r}
head(ldf[1])
```
drop first rows and column row
```{r}
# Function to process a single dataframe
process_dataframe2 <- function(df) {
  # Create a new vector "colnames1" and store the values of row 4
  colnames1 <- as.character(df[5, ])
  
  # Remove rows 1, 2, 3, and 5
  df <- df[-c(1, 2, 3, 4,6), ]
  
  # Reset row numbers
  rownames(df) <- NULL
  
  # Set the new column names as the values in vector colnames1
  colnames(df) <- colnames1
  
  # Change the name of column 1 to "Agency.Name"
  colnames(df)[1] <- "Agency.Name"

  #change the names of column 10 and 11 to Year and Month
  colnames(df)[10] <- "Year"
  colnames(df)[11] <- "Month"

  ## Find the row with "Summary Offense by Index" in the first column
  sum_row_remove <- which(df[[1]] == "Summary Offense by Index")

  ##remove 
  df <- df[-sum_row_remove, ]
  
  return(df)
}

# Apply the function to each dataframe in the list
ldf1<- lapply(ldf, process_dataframe2)

# Combine all dataframes into a single dataframe
combined_df <- bind_rows(ldf1)

# Display the combined dataframe
head(combined_df)
```
rename columns
#Murder and Nonnegligent Homicide	Forcible Rape	Robbery	Aggravated Assault	Burglary	Larceny - Theft	Motor Vehicle Theft	Arson
```{r}
col_names <- c("Agency.Name", 
              "Murder and Nonnegligent Homicide",	
              "Forcible Rape",	
              "Robbery",	
              "Aggravated Assault",	
              "Burglary",	
              "Larceny - Theft",	
              "Motor Vehicle Theft",	
              "Arson",
              "Year",
              "Month"

)

cdf1 <- select(combined_df, col_names)
```
set the new column names
```{r}
# New column names
  final_col_names <- c("Agency Name", "Murder", "Rape", "Robbery",
                       "Agg Assault", "Burglary", "Larceny", "MVT", "Arson", "Month", "Year")
  # Rename the columns
  names(cdf1) <- final_col_names
```
make the base dataset to join back to that accounts for non-reporting months
```{r}
# Using expand.grid to generate all combinations of unique values from three columns
all_combinations <- expand.grid(
  'Agency Name' = unique(cdf1$`Agency Name`),
  Year = unique(cdf1$Year),
  Month = unique(cdf1$Month)
)
```
join the combined df to this base dataset - now we know if data is missing for certain agencies for certain months - rather than just calculating the counts based on whether an agency reported a crime in that time period
```{r}
# Join the data frames
joined_df <- merge(all_combinations, cdf1, by = c("Agency Name", "Year", "Month"), all.x = TRUE)

# View the result
print(joined_df)
```
are all time periods and agencies accounted for? should have an equal number of each in terms of records
```{r}
# Counting frequency of each value in Column1
freq_Column1 <- table(joined_df$`Agency Name`)
print("Frequency of Column1:")
print(freq_Column1)

# Counting frequency of each value in Column2
freq_Column2 <- table(joined_df$Year)
print("Frequency of Column2:")
print(freq_Column2)

# Counting frequency of each value in Column3
freq_Column3 <- table(joined_df$Month)
print("Frequency of Column3:")
print(freq_Column3)
####we are all set. consistent number of records for each unique value in column now.
```
did we create some NA's?
```{r}
colSums(is.na(joined_df))
```
change NA to NR
```{r}
# Replace NA in all columns except 'AgencyName', 'Year', and 'Month' with "NR"
final_df <- joined_df %>%
  mutate_if(!names(.) %in% c("Agency Name", "Year", "Month"), ~ifelse(is.na(.), "NR", .))

# View the modified DataFrame
print(final_df)
```
reorder columns and done
```{r}
# Specified order for the columns
column_order <- c("Agency Name", "Murder", "Rape", "Robbery", 
                  "Agg Assault", "Burglary", "Larceny", "MVT", "Arson",
                  "Year", "Month")

# Reorder columns based on the specified order
final_df <- final_df[, column_order]
```
write it out!
```{r}
# Specify the folder path
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Nevada\\Formatted Data"

# Create the full file path
file_path <- file.path(folder_path, "nv_jan23_present.csv")

# Write the data frame to a .csv file
write.csv(final_df, file = file_path, row.names = FALSE)
```
