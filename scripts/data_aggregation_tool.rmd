---
title: "ben/jeff collector"
output: github_document
started: "07-23-2024"
updated: "08-09-2024"
updated: "08-19-2024"
finalish version: "08-30-2024"
---
read in the data from the ben/jeff folder
```{r}
library(tidyverse)
library(magrittr)
library(dplyr)
library(readr)
library(stringr)
library(zoo)
library(ggplot2)
```
directory path where the BEFF files are stored
```{r}
# sharepoint endpoint where the individual datasets are stored
data_dir <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\_Ben and Jeff work"
```
describe all the csv's coming in - just a general snippet to take a look at the raw data format
```{r}
# Function to get information about each CSV file
get_csv_info <- function(file) {
  df <- read_csv(file)
  data.frame(
    file_name = basename(file),
    num_columns = ncol(df),
    column_names = paste(names(df), collapse = ", "),
    column_formats = paste(sapply(df, class), collapse = ", ")
  )
}

# get a list of all the names and convert to file paths so we can run the function
file_paths <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

# Apply the function to each CSV file and combine the results into a single dataframe
csv_info_df <- map_df(file_paths, get_csv_info)

# Take a quick look
head(csv_info_df)
```
read everything in, extract the month/year and do the initial processing
```{r}
# Function to read all CSV files in a folder and save them as data frames in a list
read_csvs <- function(folder_path) {
  # List all CSV files in the directory
  file_paths <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)
  
  # Debug: Check if any files are listed
  if (length(file_paths) == 0) {
    stop("No CSV files found in the specified directory.")
  } else {
    message("Processing ", length(file_paths), " files.")
  }
  
  # Function to read a single CSV file
  read_csv_file <- function(file_path) {
    # Debug: Check the file path
    message("Reading file: ", file_path)
    
    # Attempt to read the CSV file
    tryCatch({
      df <- read_csv(file_path, show_col_types = FALSE)
      return(df)
    }, error = function(e) {
      warning("Failed to read: ", file_path, " Error: ", e$message)
      return(NULL)  # Return NULL if the file cannot be read
    })
  }
  
  # Read all CSV files and save them as data frames in a list
  df_list <- lapply(file_paths, read_csv_file)
  
  # Name each element in the list with the corresponding file name (without extension)
  names(df_list) <- tools::file_path_sans_ext(basename(file_paths))
  
  return(df_list)
}

# read'er in
ldf <- read_csvs(data_dir)

# Take'er look
head(ldf[1])
```
let's get the unique number of agencies at the beginning
```{r}
# Function to get the count of unique 'Agency Name' in each csv
get_unique_agency_count <- function(df) {
  length(unique(df$`Agency Name`))
}

# Apply the function to each dataframe in the list and store the results
unique_agency_counts <- map(ldf, get_unique_agency_count)
total_agency_raw <- sum(unlist(unique_agency_counts))
head(total_agency_raw)
##332 as of this writing this and counting...why do we lose agencies at the end?
##journal entry 547 - we now have 353 agencies and counting
##friday before 9/4 launch and we have 356!
```
format everything
```{r}
# Define the format_cols function
format_cols <- function(df) {
  # Remove the Arson column
  df <- df[, !(names(df) %in% "Arson")]
  
  # Convert specified columns to character
  char_cols <- c("Agency Name", "State")
  for (col in char_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.character(df[[col]])
    }
  }
  
  # Convert specified columns to numeric
  num_cols <- c("Murder", "Rape", "Robbery", "Aggravated Assault", "Burglary", 
                "Theft", "Motor Vehicle Theft", "Month", "Year")
  for (col in num_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  return(df)
}

# Apply to all dataframes in the list
ldf1 <- lapply(ldf, format_cols)

# What do we see
head(ldf1[1])
```
another check that after formatting we still have the same number of agencies before binding
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts1 <- map(ldf1, get_unique_agency_count)

# what is the sum of all those raw counts
total_agency_raw1 <- sum(unlist(unique_agency_counts1))

# Print the results
head(total_agency_raw1)
#353 matches up
#356 matches up!
```
next...standardize the columns
```{r}
# Ensure all data frames have the same columns and column types
all_columns <- Reduce(union, lapply(ldf1, names))

# Function to ensure all data frames have the same columns
standardize_columns <- function(df, all_columns) {
  missing_cols <- setdiff(all_columns, names(df))
  for (col in missing_cols) {
    df[[col]] <- NA
  }
  return(df[all_columns])
}

# Apply the standardize_columns function to each dataframe in the list
ldf2 <- lapply(ldf1, standardize_columns, all_columns = all_columns)

#make sure we're good
head(ldf2[1])
#still have those few .csv's we saw get read in earlier that have the extra empty columns
```
another check that after formatting we still have the same number of agencies before binding
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts2 <- map(ldf2, get_unique_agency_count)

# what is the sum of all those raw counts
total_agency_raw2 <- sum(unlist(unique_agency_counts2))

# Print the results
head(total_agency_raw2)
#353 matches up
#356 matches up!
```
get rid of the extra blank lgl formatted columns that plague our data
```{r}
acceptable_names <- c("Agency Name", "Murder", "Rape", "Robbery", "Aggravated Assault", 
"Burglary", "Theft", "Motor Vehicle Theft", "Year", "Month", "State")

ldf3 <- lapply(ldf2, function(df) {
  df[, (names(df) %in% acceptable_names)]
})

head(ldf3[1])
```
another check that after formatting we still have the same number of agencies before binding
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts3 <- map(ldf3, get_unique_agency_count)

# what is the sum of all those raw counts
total_agency_raw3 <- sum(unlist(unique_agency_counts3))

# Print the results
head(total_agency_raw3)
#353 matches up
#356 matches up!
```
stop the process if there is a dataframe that does not have each of the acceptable names and print
```{r}
# Initialize an empty list to store the names of dataframes with missing columns
df_missing_columns <- list()

# Function to check if a dataframe has all the acceptable column names
check_columns <- function(df, df_name, acceptable_names) {
  missing_cols <- setdiff(acceptable_names, colnames(df))
  if (length(missing_cols) > 0) {
    df_missing_columns[[df_name]] <- missing_cols  # Add to the list if columns are missing
  }
}

# Loop through the dataframes and check each one
for (df_name in names(ldf3)) {
  check_columns(ldf3[[df_name]], df_name, acceptable_names)
}

# Review the dataframes that are missing columns
if (length(df_missing_columns) > 0) {
  print("The following dataframes are missing columns:")
  print(df_missing_columns)
} else {
  print("All dataframes have the required columns.")
}
```
combine and check it out
```{r}
# combine everything together 
combined_df <- bind_rows(ldf3)

# Step 2: Reset row names
rownames(combined_df) <- NULL

#select out acceptable columns and take a look just to make sure
combined_df <- combined_df %>% select(acceptable_names)
head(combined_df)
#looking good.
```
city state column for getting unique number of agencies
```{r}
#create the city_state column here for a unique ID
combined_df <- combined_df %>% mutate(city_state = paste(`Agency Name`, State, sep = ", "))

#31,442 obs
#32,036 obs before launch
length(unique(combined_df$city_state))
#351 agencies
#356
length(unique(combined_df$`Agency Name`))
#342 - duplicates match up!
```
what's wrong with the allen's of the world
```{r}
# Ensure NA's are explicitly marked as NA in designated columns
cdf <- combined_df %>%
  mutate(
    Murder = ifelse(is.na(Murder), NA, Murder),
    Rape = ifelse(is.na(Rape), NA, Rape),
    Robbery = ifelse(is.na(Robbery), NA, Robbery),
    `Aggravated Assault`= ifelse(is.na(`Aggravated Assault`), NA, `Aggravated Assault`),
    Burglary = ifelse(is.na(Burglary), NA, Burglary),
    Theft = ifelse(is.na(Theft), NA, Theft),
    `Motor Vehicle Theft` = ifelse(is.na(`Motor Vehicle Theft`),NA, `Motor Vehicle Theft`)
  )
```
create variables for audit
```{r}
# Get the current date
update_current_date <- function() {
  today <- Sys.Date()
  day_of_month <- as.integer(format(today, "%d"))
  
  if (day_of_month >= 15) {
    current_date <<- today
  } else {
    current_date <<- seq(today, length = 2, by = "-1 month")[2]
  }
}

# Run the function to set current_date
update_current_date()

# To demonstrate:
print(current_date)  # prints the calculated date

# Extract the current year and month
current_year <- year(current_date)
current_month <- month(current_date)

# Calculate the previous months
previous_month_date <- current_date %m-% months(1)
two_months_previous_date <- current_date %m-% months(2)
three_months_previous_date <- current_date %m-% months(3)

# Extract the year and month for the previous months
previous_month_year <- year(previous_month_date)
previous_month_month <- month(previous_month_date)

two_months_previous_year <- year(two_months_previous_date)
two_months_previous_month <- month(two_months_previous_date)

three_months_previous_year <- year(three_months_previous_date)
three_months_previous_month <- month(three_months_previous_date)

# Print the results
cat("Current Year:", current_year, "Current Month:", current_month, "\n")
cat("Previous Month - Year:", previous_month_year, "Month:", previous_month_month, "\n")
cat("Two Months Previous - Year:", two_months_previous_year, "Month:", two_months_previous_month, "\n")
cat("Three Months Previous - Year:", three_months_previous_year, "Month:", three_months_previous_month, "\n")
```
drop everything from current year/month and current year/previous month
```{r}
# Filter out observations with the current month and year or previous month and current year
cdf <- cdf %>%
  filter(
    !(Year == current_year & Month == current_month) &
    !(Year == current_year & Month == previous_month_month)
  )
```
new filter for finding non-reporters without current blank records
```{r}
## Step 1: Identify the most recent observation for each agency in a dataframe for analysis
most_recent_obs <- cdf %>%
  group_by(`Agency Name`) %>%
  slice_max(order_by = as.Date(paste(Year, Month, "01", sep = "-")), n = 1) %>% 
  ungroup()

# Step 2: Filter records where the most recent report was older than the current sample month
undesirables_recency <- most_recent_obs %>%
  filter(Month < two_months_previous_month & Year == two_months_previous_year |
         Month >= two_months_previous_month & Year < two_months_previous_year 
         )

# Step 3: filter records that are missing current sample murder data
undesirables_na_current <- most_recent_obs %>%
  filter(Year == two_months_previous_year & 
         Month == two_months_previous_month & 
         is.na(Murder))

# Step 3a: Filter records that are missing historical murder data (could have current)
undesirables_na_historical <- cdf %>%
  filter(Year <= two_months_previous_year &
         Month < two_months_previous_month &
         is.na(Murder))

# Step 4: Combine the results
undesirables <- bind_rows(undesirables_recency, undesirables_na_current, undesirables_na_historical)

# Step 5: Remove duplicates by 'city_state' column
undesirables <- undesirables %>%
  distinct(city_state, .keep_all = TRUE)
```
without non-reporters for 45 day lag month //first month is June
```{r}
# Get unique values from city_state unique id to remove same sample calculations table
remove_agencies <- unique(undesirables$city_state)

# Filter out rows where city_state is in the list of values_to_remove
cdf_nwcounts <- cdf %>% filter(!city_state %in% remove_agencies)
```
vc/pc groupings
```{r}
# Add new columns for violent and property crime
cdf_vcpc<- cdf_nwcounts %>% 
    mutate(
    vio_crime = rowSums(select(., Murder, Rape, Robbery, `Aggravated Assault`), na.rm = TRUE),
    prop_crime = rowSums(select(., Burglary, Theft, `Motor Vehicle Theft`), na.rm = TRUE)
  )

# save a copy for later calcs
cdf_vcpc_nats <- cdf_vcpc

# slim it down to the essentials to join back to the main dataframe
cdf_vcpc <- cdf_vcpc %>% select(city_state, vio_crime, prop_crime, Year, Month)
```
join to main dataframe
```{r}
#add vc/pc counts back to main df and create a new df var
cdf1 <- merge(cdf, cdf_vcpc, by = c("city_state", "Month", "Year"), all.x = TRUE)
```
add population figures for nationwide descriptors
```{r}
#read in the ref_df file from sharepoint
ref_df <- read.csv("C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data\\final_sourcing.csv")

#make a city_state column for matching
ref_df <- ref_df %>% mutate(city_state = paste(Agency, State, sep = ", "))

#slim it down for now
ref_df1 <- ref_df %>% select(city_state, Population)

# add population data merging by city/state col
cdf_vcpc_nats <- merge(cdf_vcpc_nats, ref_df1, by = "city_state", all.x = TRUE)
```
drop cdf1 extra columns after fixing
```{r}
#clean up names and drop old names
cdf2 <- cdf1 %>%
  mutate(`Violent Crime` = vio_crime,
          `Property Crime` = prop_crime, ) %>%
            select(-city_state, -vio_crime, -prop_crime)

#same for table used for sample calcs + format pop var and create counter for agency # calc
cdf_vcpc_nats <- cdf_vcpc_nats %>%
  mutate(`Violent Crime` = vio_crime,
          `Property Crime` = prop_crime,
          Population = as.numeric(Population),
           agency_num = 1) %>%
           select(-vio_crime, -prop_crime)
```
calculate and add nationwide counts
```{r}
nationwide_counts <- cdf_vcpc_nats %>%
  group_by(Year, Month) %>%
  summarise(
    Murder= sum(Murder, na.rm = TRUE),
    Rape= sum(Rape, na.rm = TRUE),
    Robbery= sum(Robbery, na.rm = TRUE),
    `Aggravated Assault`= sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary= sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    `Violent Crime` = sum(`Violent Crime`, na.rm = TRUE),
    `Property Crime` = sum(`Property Crime`, na.rm = TRUE),
    `Population Total` = sum(Population, na.rm = TRUE),
    Agency_num = sum(agency_num, na.rm = TRUE),
    .groups = 'drop'
  )
# Display the aggregate level dataframe
head(nationwide_counts)
```
add the nationwide counts to the sample for the viz
```{r}
# Add values for agency name field so we can bind
nationwide_counts$`Agency Name` <- "Nationwide Count"

# also need state values and column
nationwide_counts$State <- "All Agencies"
```
create population groupings and then generate 
<100k, 100k to 250k, 250-1mi, million +
pop groupings for within nationwide
```{r}
# Separate data into different population groups
population_groups <- cdf_vcpc_nats %>%
  mutate(Population_Group = case_when(
    Population < 100000 ~ "<100k",
    Population >= 100000 & Population < 250000 ~ "100k-250k",
    Population >= 250000 & Population < 1000000 ~ "250k-1mn",
    Population >= 1000000 ~ "1mn+"
  ))

# Summarize by population group, year, and month
nationwide_subsets <- population_groups %>%
  group_by(Year, Month, Population_Group) %>%
  summarise(
    Murder = sum(Murder, na.rm = TRUE),
    Rape = sum(Rape, na.rm = TRUE),
    Robbery = sum(Robbery, na.rm = TRUE),
    `Aggravated Assault` = sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary = sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    `Violent Crime` = sum(`Violent Crime`, na.rm = TRUE),
    `Property Crime` = sum(`Property Crime`, na.rm = TRUE),
    `Population Total` = sum(Population, na.rm = TRUE),
    Agency_num = sum(agency_num, na.rm = TRUE),
    .groups = 'drop'
  )

# Separate out each population group if needed
group_100k <- nationwide_subsets %>% filter(Population_Group == "<100k")
group_100k_250k <- nationwide_subsets %>% filter(Population_Group == "100k-250k")
group_250k_1mil <- nationwide_subsets %>% filter(Population_Group == "250k-1mi")
group_1mil <- nationwide_subsets %>% filter(Population_Group == "1mi+")
```
add the nationwide counts to the sample for the viz
```{r}
# Add values for agency name field so we can bind
nationwide_subsets1 <- nationwide_subsets %>%
                        rename(`Agency Name` = Population_Group)

# also need state values and column
nationwide_subsets1$State <- "All Agencies in Grouping"
```
bind the nationwide counts to the bottom
```{r}
cdf2 <- bind_rows(cdf2, nationwide_counts, nationwide_subsets1)
head(cdf2)
```
#sneak in the PR data and get 12mo mvsums
```{r}
#pr <- read.csv("C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Agencies\\Puerto Rico\\Crime for Major Cities (English) (2).csv")
```
#clean up reshape
```{r}
# Reshape into wide format
#wide_pr <- pr %>%
#  pivot_wider(names_from = PBI_CRIMEN_codigo, values_from = PBI_CRIMEN_Crime_Count,
# values_fill = 0)

# View the reshaped data
#head(wide_pr)
```
#make some new columns
```{r}
# Aggregating specific columns
# 09A - murder;11a-c rape;12o robbery,13a agg assault; 220 burglary;23a-h theft;240 mvt
#pr_counts <- wide_pr %>%
#  mutate(
 #   Murder = `09A`, 
  #  Rape = `11A`, #no B and C reported   
  #  Robbery = `120`,
  #  `Aggravated Assault` = `13A`,
  #  Burglary = `220`,
  #  Theft = `23A` + `23B` + `23C` + `23D` + `23E` + `23F` + `23G` + `23H`,
  #  `Motor Vehicle Theft` = `240`
  #)

```
fix remaining columns and select out 
```{r}
# Rename municipality column and convert month to numeric
#pr_counts <- pr_counts %>%
#  rename(`Agency Name` = Municipalities_Name_1,
#          Year = Date_Date_Year) %>%   # Rename municipality column
#  mutate(Month = match(Date_Date_Month, month.name))   # Convert month to numeric

#provisional title
#pr_counts$State <- "Puerto Rico"

#make sure we only have the columns that the rest of the dataset has
#pr_counts <- pr_counts %>% select(acceptable_names)
```

bind to the end
```{r}
#cdf2 <- bind_rows(cdf2, pr_counts)
```
get mvs_12mo for all crime categories and groupings
```{r}
# Function to calculate 12-month cumulative sum 
mvs_12mo <- function(df) {
  require(magrittr)
  df <- df %>%
    arrange(Year, Month) %>%
    group_by(`Agency Name`, State) %>%
    mutate(across(c(Murder, Burglary, Rape, Robbery, `Aggravated Assault`, `Motor Vehicle Theft`, Theft, `Violent Crime`, `Property Crime`), 
                  ~rollapply(.x, width = 12, FUN = sum, align = "right", fill = NA, partial = TRUE),
                  .names = "{col}_mvs_12mo")) %>%
    ungroup()
  return(df)
}

# Apply the function to the single dataframe
df_mvs_12mo1 <- mvs_12mo(cdf2)

# Print the result to verify
head(df_mvs_12mo1)
```
drop 2017 - just needed it for 12mo MVS to start in 2018
```{r}
# we don't have 12 mo mvs for 2017 so it looks weird
df_mvs_12mo1 <- df_mvs_12mo1 %>% filter(Year != 2017)
```
make a new city_state field just to check no agencies were kicked, etc.
```{r}
# one last check
df_mvs_12mo1 <- df_mvs_12mo1 %>% mutate(city_state = paste(`Agency Name`, State, sep = ", "))
# city state unique id
length(unique(df_mvs_12mo1$city_state))
# duplicate agency names
length(unique(df_mvs_12mo1$`Agency Name`))
```
join ref to sample
```{r}
df_w_ref <- df_mvs_12mo1 %>%
  left_join(ref_df, by = "city_state")
```
remove non-current reporter
```{r}
#replace population values with Population values
colSums(is.na(df_w_ref))
df_w_ref$Population <- ifelse(is.na(df_w_ref$Population), df_w_ref$`Population Total`, df_w_ref$Population)
colSums(is.na(df_w_ref))

#fix non-nationwide sample values for viz
df_w_ref$Agency_num <- ifelse(is.na(df_w_ref$Agency_num), 1, df_w_ref$Agency_num)
colSums(is.na(df_w_ref))

#drop population total column after values are transferred to population
df_w_ref <- df_w_ref %>% select(-`Population Total`)
```
clean up schema for oscar
```{r}
#keep in both state fields for eventual auditing purposes (check merge success)
final_data <- df_w_ref %>%
  rename(
    State = State.x,
    State_ref = State.y
  )
```
remove bad month for june if all na
```{r}
#this ensure that the YTD figures are apples to apples and not understate %change
final_data1 <- final_data %>%
  filter(!(Year == two_months_previous_year & Month == two_months_previous_month & is.na(Murder)))
```
remove missing months consecutively from current month
-scottsdale issue
-drop months if all everything
```{r}
# Need a list of crime type names to check for below
ctypes <- c("Murder", "Rape", "Robbery", "Aggravated Assault", "Burglary", 
                "Theft", "Motor Vehicle Theft")

crime_data <- final_data1 %>%
  mutate(date = as.Date(paste(Year, Month, "01", sep = "-"), format = "%Y-%m-%d"))

# Initialize a dataframe to store removed observations
removed_observations <- data.frame()

# Get the list of unique agencies
unique_agencies <- unique(crime_data$`Agency Name`)

# Initialize an empty dataframe to store the cleaned data
cleaned_data <- data.frame()

# Loop over each agency
for (agency in unique_agencies) {
  
  # Subset data for the current agency
  agency_data <- subset(crime_data, `Agency Name` == agency)
  
  # Sort the data by date in descending order
  agency_data <- agency_data[order(agency_data$date, decreasing = TRUE), ]
  
  # Loop through the data month by month
  remove_flag <- TRUE
  i <- 1
  while (i <= nrow(agency_data)) {
    
    # Check if all crime types in the specified columns are NA
    if (remove_flag && all(is.na(agency_data[i, ctypes]))) {
      
      # Add the observation to the removed_observations dataframe
      removed_observations <- rbind(removed_observations, agency_data[i, ])
      
      # Remove the observation from the original data
      agency_data <- agency_data[-i, ]
      
    } else {
      # Once a non-NA value is found, stop further removals for this agency
      remove_flag <- FALSE
      i <- i + 1
    }
  }
  
  # Restore the original order of the agency_data
  agency_data <- agency_data[order(agency_data$date, decreasing = FALSE), ]
  
  # Append the cleaned data back to the main cleaned_data dataframe
  cleaned_data <- rbind(cleaned_data, agency_data)
}

# Restore the original order of the removed_observations
removed_observations <- removed_observations[order(removed_observations$date, decreasing = FALSE), ]

# Subset to a different dataframe
subset_removed <- removed_observations

head(subset_removed)
```
add a time stamp column
```{r}
# For the careful but forgetful few
cleaned_data$Last.Updated <- Sys.Date()
```
prepare a dataframe of all component agencies into sample for sourcing table
```{r}
sample_cities <- cdf_vcpc_nats %>%
  group_by(city_state) %>%
  slice(1) %>%
  ungroup()
```
write it out!
```{r}
# Specify the folder path
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data"

# Create the full file path
file_path <- file.path(folder_path, "final_sample.csv")

# Write the data frame to a .csv file
write.csv(cleaned_data, file = file_path, row.names = FALSE)

# Write the data frame to the data folder in Github repo
write.csv(cleaned_data, "data/final_sample.csv", row.names = FALSE)
```
audit lists - 2 tables - non-reporters removed and non-reporters 2 months
```{r}
# Punch out all auditing tables. the first two sum to the third. pop missing is another barrel of monkeys
write.csv(undesirables_na_current, "scripts/auditing/missing_current.csv", row.names = FALSE)
write.csv(undesirables_na_historical, "scripts/auditing/missing_historical.csv", row.names = FALSE)
write.csv(undesirables_recency, "scripts/auditing/no_reported_data_past_two_months.csv", row.names = FALSE)
write.csv(remove_agencies, "scripts/auditing/agencies_removed_from_sample.csv", row.names = FALSE)

# Sample Cities file for Sourcing table base
write.csv(sample_cities, "data/sample_cities.csv", row.names = FALSE)
file_path3 <- file.path(folder_path1, "sample_cities.csv" )
write.csv(sample_cities, file = file_path3, row.names = FALSE)

# File Path for Jeff local
folder_path1 <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Data Auditing and Validation"
# Create the full file path - for jeff
file_path1 <- file.path(folder_path1, "jample.csv")
write.csv(cleaned_data, file = file_path1, row.names = FALSE)
```