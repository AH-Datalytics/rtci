---
title: "ohio ucr processing"
output: pdf_document
date: "2024-05-01"
updated: "2024-06-06"
updated: "2024-07-22"
---
```{r}
library(lubridate)
library(tidyverse)
library(stringr)
library(readr)
```
not sure if it's the same file month to month or not so let's do a bland read.in
```{r}
# Set the path to the directory containing the CSV files
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Ohio\\State UCR"

# List all CSV files in the directory
file_list <- list.files(path = folder_path, pattern = "\\.csv$", full.names = TRUE)

# Function to read and process each file
process_file <- function(file_name) {
  # Read the CSV file
  df <- read_csv(file_name, show_col_types = FALSE)
  
  df$month_n <- match(df$month, month.name)
  
  # Create new incident date variable
  df$Incident_Date <- as.Date(paste0(df$month_n,"/01/",df$year)  ,format = "%m/%d/%Y")
  

  
  return(df)
}

# Apply the function to each file and store results in a list of data frames
ldf <- lapply(file_list, process_file)
```
what does the top look like
```{r}
head(ldf[1])
```
let's get the crimes as columns
```{r}
#create a function that will transform all df's in the list to wide
transform_to_wide <- function(df) {
  # Pivot the dataframe to a wider format
  df_wide <- df %>%
    select(-nibrs_code) %>% 
    pivot_wider(names_from = nibrs_description, values_from = total)

  return(df_wide)
}

#apply function to list
ldf_wide <- lapply(ldf, transform_to_wide)
# Print the resulting dataframe
print(ldf_wide[1])
```
remove records with NA in the year column - convert NA counts to 0 - also converts month field to numeric representation
jan ==1, feb ==2, etc.
```{r}
#function to do both
clean_df <- function(df) {
  # Filter out rows where 'year' and 'month' column has NA values
  clean_data <- df %>%
    filter(!is.na(year) | !is.na(month))
  
  # Convert all columns (except the first one) to numeric and replace NA with 0
  clean_data1 <- clean_data %>%
    mutate(across(.cols = -(1:6), ~ as.numeric(replace(., is.na(.), 0))))
  
  return(clean_data1)
}

#apply function to dataframes in list
ldf3 <- lapply(ldf_wide, clean_df)
print(ldf3[1])

```
sum column values to get SRS figures from NIBRS
From NIBRS OFFENSE CODES MANUAL 2011
```{r}
#murder 09A - Murder & Nonnegligent Manslaughter

#rape - 11A - Forcible Rape

#agg assault - 13A - Aggravated Assault

#robbery - 120 - Robbery

#burglary - 220 - Burglary/Breaking & Entering

#Larceny/Theft Offenses to sum - 23H
#Pocket-picking Property,  Purse-snatching Property,  Shoplifting Property,  Theft From Building Property,  Theft From Coin-Operated Machine or Device Property,  Theft From Motor Vehicle Property,  Theft of Motor Vehicle Parts or Accessories Property,All Other Larceny Property

#Pocket-picking, Theft From Coin-Operated Machine not found - but no big
############ALSO Add 23H/23C column



process_larceny <- function(df) {
  # Define the columns related to larceny
  columns_to_larc <- c(
    "Pocket-picking", "Purse-snatching", "Shoplifting", "Theft From Building",
    "Theft From Coin-Operated Machine or Device", "Theft From Motor Vehicle",
    "Theft From Motor Vehicle Parts or Accessories", "All Other Larceny"
  )
  
  # Check if all specified columns exist in the dataframe
  missing_cols <- setdiff(columns_to_larc, names(df))
  if (length(missing_cols) > 0) {
    warning("The following columns are missing in the dataframe and will be excluded from the sum: ", paste(missing_cols, collapse=", "))
    columns_to_larc <- setdiff(columns_to_larc, missing_cols)
  }
  
  # Calculate the sum of the specified columns if any exist
  if (length(columns_to_larc) > 0) {
    df$Larceny <- rowSums(df[, columns_to_larc], na.rm = TRUE)
  } else {
    df$Larceny <- 0  # Set Larceny to 0 if no columns are available for summing
  }
  
  return(df)
}

#mvt - 240 - Motor Vehicle Theft

########################
########################
#arson -200 - Arson

#apply function and print out the first dataframe
ldf3_larc <- lapply(ldf3, process_larceny)
```
check larceny column
```{r}
print(ldf3_larc[1])
```

issues with murder not found in one of the dataframes
```{r}
# Function to extract and compare column names
compare_column_names <- function(list_df) {
  # Extract column names from each dataframe in the list
  col_names_list <- lapply(ldf3_larc, names)
  
  # Find unique and common column names
  all_names <- unique(unlist(col_names_list))
  common_names <- Reduce(intersect, col_names_list)
  
  # Determine unique columns for each dataframe
  unique_cols <- lapply(col_names_list, setdiff, common_names)
  
  # Print or return results
  list(all_column_names = all_names,
       common_column_names = common_names,
       unique_column_names_per_df = unique_cols)
}

# Apply the function and capture the results
column_differences <- compare_column_names(ldf3_larc)

# Print the results
print(column_differences)
```
clearly not every data frame has the same columns as some agencies didn't report or didn't report a certain index crime?

drop unnecessary columns
```{r}
###another attempt
# List of required column names
required_columns <- c("agency_name", "Murder & Nonnegligent Manslaughter",
                      "Rape", "Robbery", "Aggravated Assault", "Burglary/Breaking & Entering",
                       "Larceny", "Motor Vehicle Theft", "Arson", "month_n", "year")

# Function to check and add missing columns, then select required columns
adjust_dataframes <- function(df, required_columns) {
  # Check for missing columns and add them if they are missing
  missing_columns <- setdiff(required_columns, names(df))
  if (length(missing_columns) > 0) {
    for (col in missing_columns) {
      df[[col]] <- NA  # Add missing columns with NA values
    }
  }
  
  # Select only the required columns (ensures correct order as well)
  df <- df[, required_columns, drop = FALSE]
  
  return(df)
}

# Apply the function to each dataframe in the list
adjusted_list_df <- lapply(ldf3_larc, adjust_dataframes, required_columns = required_columns)

# Print the results to verify the adjustment
print(adjusted_list_df)
```
row bind the list together
```{r}
combined_df <- do.call(rbind, adjusted_list_df)
# New column names
  final_col_names <- c("Agency Name","Murder", "Rape", "Robbery",
                       "Agg Assault", "Burglary", "Larceny", "MVT",
                       "Arson", "Month", "Year")
  # Rename the columns
  names(combined_df) <- final_col_names
```
do we have the right number of records?



create a dataframe that is every combination of agency + year + month - then merge the combined_df back - do we want to keep the na's? or do we want to write a code that it was un-reported for that time period?
```{r}
# Using expand.grid to generate all combinations of unique values from three columns
all_combinations <- expand.grid(
  'Agency Name' = unique(combined_df$`Agency Name`),
  Year = unique(combined_df$Year),
  Month = unique(combined_df$Month)
)
```
join the combined df to this base dataset - now we know if data is missing for certain agencies for certain months - rather than just calculating the counts based on whether an agency reported a crime in that time period
```{r}
# Join the data frames
joined_df <- merge(all_combinations, combined_df, by = c("Agency Name", "Year", "Month"), all.x = TRUE)

# View the result
head(joined_df)
```
are all time periods and agencies accounted for? should have an equal number of each in terms of records
```{r}
# Counting frequency of each value in Column1
freq_Column1 <- table(joined_df$`Agency Name`)
print("Frequency of Column1:")
print(freq_Column1)

# Counting frequency of each value in Column2
freq_Column2 <- table(joined_df$Year)
print("Frequency of Column2:")
print(freq_Column2)

# Counting frequency of each value in Column3
freq_Column3 <- table(joined_df$Month)
print("Frequency of Column3:")
print(freq_Column3)
####we are all set. consistent number of records for each unique value in column now.
```
did we create some NA's?
```{r}
colSums(is.na(joined_df
            ))
```
change NA to NR
```{r}
# Replace NA in all columns except 'AgencyName', 'Year', and 'Month' with "NR"
final_df <- joined_df %>%
  mutate_if(!names(.) %in% c("Agency Name", "Year", "Month"), ~ifelse(is.na(.), "NR", .))

# View the modified DataFrame
head(final_df)
```
reorder columns and done
```{r}
# Specified order for the columns
column_order <- c("Agency Name", "Murder", "Rape", "Robbery", 
                  "Agg Assault", "Burglary", "Larceny", "MVT", "Arson",
                  "Year", "Month")

# Reorder columns based on the specified order
final_df <- final_df[, column_order]
```
add a column for State and then we're done.
```{r}
# Specify the value for the "State" column
state_value <- "Ohio"

# Add the "State" column to the data frame
final_df$State <- state_value
```
write it out!
```{r}
# Specify the folder path
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Ohio\\Formatted Data"

# Create the full file path
file_path <- file.path(folder_path, "oh_jan23_present.csv")

# Write the data frame to a .csv file
write.csv(final_df, file = file_path, row.names = FALSE)
```