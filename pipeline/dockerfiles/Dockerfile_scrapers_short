# install a python docker
FROM python:3.10

# specify the working directory for further docker commands
WORKDIR /rtci

# copy this directory (`.`) into the docker container filesystem
COPY . /rtci

# install packages from `pipeline/requirements.txt file
# (anytime you need to add a new package to requirements,
# you'll have to rebuild the image and container)
RUN pip3 install --trusted-host pypi.python.org -r pipeline/requirements.txt

# make sure information about packages/dependencies is up to date
RUN apt-get update

# the `-y` flag automatically responds yes to prompts on install
# (wget is a command-line utility for downloading from the internet)
# (unzip is a command-line utility for unzipping zipped files downloaded from the internet)
RUN apt-get install -y wget unzip

# get the latest stable chromedriver for use by selenium scrapes, install and remove installation files
RUN wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
RUN apt install -y ./google-chrome-stable_current_amd64.deb
RUN rm google-chrome-stable_current_amd64.deb

# remove downloaded package files to clear up space in the container
RUN apt-get clean

# sets python paths within the docker container filesystem
ENV PYTHONPATH "${PYTHONPATH}:/rtci:/rtci/pipeline:/rtci/pipeline/utils:/rtci/pipeline/ops"

# move into the correct directory and run the main scrape execution script
WORKDIR /rtci/pipeline/ops
CMD ["python3", "exec_scrapes.py", "-a", "-d", "-x", "MN", "NY0303000"]