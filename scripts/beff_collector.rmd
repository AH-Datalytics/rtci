---
title: "ben/jeff collector"
output: github_document
started: "07-23-2024"
---
read in the data from the ben/jeff folder
```{r}
library(tidyverse)
library(dplyr)
library(readr)
library(stringr)
library(zoo)
```
directory path where the BEFF files are stored
```{r}
data_dir <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\_Ben and Jeff work"

file_paths <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

crime_types <- c("Agency Name",
                 "Murder", "Rape", "Robbery",
                 "Aggravated Assault", "Burglary", 
                 "Theft", "Motor Vehicle Theft", 
                 "Month", "Year")
```
describe all the csv's coming in
```{r}
# Function to get information about each CSV file
get_csv_info <- function(file) {
  df <- read_csv(file)
  data.frame(
    file_name = basename(file),
    num_columns = ncol(df),
    column_names = paste(names(df), collapse = ", "),
    column_formats = paste(sapply(df, class), collapse = ", ")
  )
}

# Apply the function to each CSV file and combine the results into a single dataframe
csv_info_df <- map_df(file_paths, get_csv_info)

head(csv_info_df)
```
read everything in, extract the month/year and do the initial processing
```{r}
# Function to read all CSV files in a folder and save them as data frames in a list
read_csvs <- function(folder_path) {
  # List all CSV files in the directory
  file_paths <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)
  
  # Debug: Check if any files are listed
  if (length(file_paths) == 0) {
    stop("No CSV files found in the specified directory.")
  } else {
    message("Processing ", length(file_paths), " files.")
  }
  
  # Function to read a single CSV file
  read_csv_file <- function(file_path) {
    # Debug: Check the file path
    message("Reading file: ", file_path)
    
    # Attempt to read the CSV file
    tryCatch({
      df <- read_csv(file_path, show_col_types = FALSE)
      return(df)
    }, error = function(e) {
      warning("Failed to read: ", file_path, " Error: ", e$message)
      return(NULL)  # Return NULL if the file cannot be read
    })
  }
  
  # Read all CSV files and save them as data frames in a list
  df_list <- lapply(file_paths, read_csv_file)
  
  # Name each element in the list with the corresponding file name (without extension)
  names(df_list) <- tools::file_path_sans_ext(basename(file_paths))
  
  return(df_list)
}

ldf <- read_csvs(data_dir)

# Print the names of the data frames in the list to verify
print(names(ldf))

head(ldf[1])
```
let's get the unique number of agencies at the beginning
```{r}
# Function to get the count of unique 'Agency Name'
get_unique_agency_count <- function(df) {
  length(unique(df$`Agency Name`))
}

# Apply the function to each dataframe in the list and store the results
unique_agency_counts <- map(ldf, get_unique_agency_count)

total_agency_raw <- sum(unlist(unique_agency_counts))

# Print the results
head(total_agency_raw)
##332 as of this writing this and counting...why do we lose agencies at the end?
```
format everything
```{r}
# Define the format_cols function
format_cols <- function(df) {
  # Remove the Arson column
  df <- df[, !(names(df) %in% "Arson")]
  
  # Convert specified columns to character
  char_cols <- c("Agency Name", "State")
  for (col in char_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.character(df[[col]])
    }
  }
  
  # Convert specified columns to numeric
  num_cols <- c("Murder", "Rape", "Robbery", "Aggravated Assault", "Burglary", 
                "Theft", "Motor Vehicle Theft", "Month", "Year")
  for (col in num_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  return(df)
}

ldf1 <- lapply(ldf, format_cols)
head(ldf1[1])
```
how many agencies are in the component files /no duplicates this way/
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts1 <- map(ldf1, get_unique_agency_count)

total_agency_raw1 <- sum(unlist(unique_agency_counts1))

# Print the results
head(total_agency_raw1)
##332 as of this writing this and counting...why do we lose agencies at the end?
```
next...standardize the columns
```{r}
# Ensure all data frames have the same columns and column types
all_columns <- Reduce(union, lapply(ldf1, names))

# Function to ensure all data frames have the same columns
standardize_columns <- function(df, all_columns) {
  missing_cols <- setdiff(all_columns, names(df))
  for (col in missing_cols) {
    df[[col]] <- NA
  }
  return(df[all_columns])
}

# Apply the standardize_columns function to each dataframe in the list
ldf2 <- lapply(ldf1, standardize_columns, all_columns = all_columns)

#change column names where they don't match - larceny to theft
rename_larceny_to_theft <- function(df) {
  if ("Larceny" %in% names(df)) {
    names(df)[names(df) == "Larceny"] <- "Theft"
  }
  return(df)
}

ldf2 <- lapply(ldf2, rename_larceny_to_theft)
head(ldf2[1])
```

make sure our agency counts are the same
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts2 <- map(ldf2, get_unique_agency_count)

total_agency_raw2 <- sum(unlist(unique_agency_counts2))

# Print the results
head(total_agency_raw2)
##332 as of this writing this and counting...why do we lose agencies at the end?
```
still have a few odd column names
```{r}
acceptable_names <- c("Agency Name", "Murder", "Rape", "Robbery", "Aggravated Assault", 
"Burglary", "Theft", "Motor Vehicle Theft", "Year", "Month", "State")

ldf3 <- lapply(ldf2, function(df) {
  df[, (names(df) %in% acceptable_names)]
})

head(ldf3[1])
```
combine and check it out
```{r}
combined_df <- do.call(rbind, ldf3)

rownames(combined_df) <- NULL

#select out acceptable columns and take a look just to make sure
combined_df <- combined_df %>% select(acceptable_names)
head(combined_df)
```
city state column for getting unique number of agencies
```{r}
combined_df <- combined_df %>% mutate(city_state = paste(`Agency Name`, State, sep = ", "))

length(unique(combined_df$city_state))
#351 agencies
#31,442 obs
length(unique(combined_df$`Agency Name`))


unique_df <- combined_df %>%
  select(city_state) %>%
  distinct()


df1<- as.data.frame(unique(combined_df$city_state))
df2<- as.data.frame(unique(combined_df$city_state))


unique(combined_df$city_state)
unique(combined_df$city_state)

merged_df <- full_join(df1, df2, by = "")

# Print the merged data frame
print("Merged Data Frame:")
print(merged_df)

# Find records without a match in df1
unmatched_in_df1 <- anti_join(df2, df1, by = "city_state")
print("Records in df2 without a match in df1:")
print(unmatched_in_df1)

# Find records without a match in df2
unmatched_in_df2 <- anti_join(df1, df2, by = "city_state")
print("Records in df1 without a match in df2:")
print(unmatched_in_df2)
```
create variables for audit
```{r}
# Get the current date
current_date <- Sys.Date()

# Extract the current year and month
current_year <- year(current_date)
current_month <- month(current_date)

# Calculate the previous months
previous_month_date <- current_date %m-% months(1)
two_months_previous_date <- current_date %m-% months(2)
three_months_previous_date <- current_date %m-% months(3)

# Extract the year and month for the previous months
previous_month_year <- year(previous_month_date)
previous_month_month <- month(previous_month_date)

two_months_previous_year <- year(two_months_previous_date)
two_months_previous_month <- month(two_months_previous_date)

three_months_previous_year <- year(three_months_previous_date)
three_months_previous_month <- month(three_months_previous_date)

# Print the results
cat("Current Year:", current_year, "Current Month:", current_month, "\n")
cat("Previous Month - Year:", previous_month_year, "Month:", previous_month_month, "\n")
cat("Two Months Previous - Year:", two_months_previous_year, "Month:", two_months_previous_month, "\n")
cat("Three Months Previous - Year:", three_months_previous_year, "Month:", three_months_previous_month, "\n")
```
drop everything from current year/month and current year/previous month
```{r}
# Filter out observations with the current month and year or previous month and year
cdf <- combined_df %>%
  filter(
    !(Year == current_year & Month == current_month) |
    !(Year == current_year & Month == previous_month_month)
  )

# Print the result
head(cdf)
```
vc/pc groupings
```{r}
# Add new columns for violent and property crime
cdf1 <- cdf %>%
    mutate(
    vio_crime = rowSums(select(., Murder, Rape, Robbery, `Aggravated Assault`), na.rm = TRUE),
    prop_crime = rowSums(select(., Burglary, Theft, `Motor Vehicle Theft`), na.rm = TRUE)
  )
```
without non-reporters for 45 day lag month //first month is June
```{r}
# First need to create a df from na_two_months_previous 
non_reporters <- na_two_months_previous %>%
  filter(is.na(Murder))

# Get unique values from the column in the separate dataframe
remove_agencies <- unique(non_reporters$`Agency Name`)

# Filter out rows where Agency_Name is in the list of values_to_remove
cdf_nwcounts<- cdf1 %>% filter(!`Agency Name` %in% remove_agencies)
```
calculate and add nationwide counts
```{r}
nationwide_counts <- cdf_nwcounts %>%
  group_by(Year, Month) %>%
  summarise(
    Murder= sum(Murder, na.rm = TRUE),
    Rape= sum(Rape, na.rm = TRUE),
    Robbery= sum(Robbery, na.rm = TRUE),
    `Aggravated Assault`= sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary= sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    `Violent Crime` = sum(vio_crime, na.rm = TRUE),
    `Property Crime` = sum(prop_crime, na.rm = TRUE),
    .groups = 'drop'
  )

# Display the aggregate level dataframe
head(nationwide_counts)
```
add the nationwide counts to the sample once it's working
```{r}
nationwide_counts$`Agency Name` <- "Nationwide Count"

nationwide_counts$State <- "All Agencies"
```
drop cdf1 extra columns after fixing
```{r}
cdf2 <- cdf1 %>%
  mutate(`Violent Crime` = vio_crime,
          `Property Crime` = prop_crime ) %>%
            select(-city_state, -vio_crime, -prop_crime)

```
bind the nationwide counts to the bottom
```{r}
cdf2 <- bind_rows(cdf2, nationwide_counts)
head(cdf2)
```
audit 2 and 3 months
```{r}
# Filter records with any NA values for two months previous
na_two_months_previous <- cdf2 %>%
  filter(Month == two_months_previous_month & Year == two_months_previous_year) %>%
  filter(rowSums(is.na(.)) > 0)

# Filter records with any NA values for three months previous
na_three_months_previous <- cdf2 %>%
  filter(Month == three_months_previous_month & Year == three_months_previous_year) %>%
  filter(rowSums(is.na(.)) > 0)

# Print the data frames
print("Records with NA values two months previous:")
print(na_two_months_previous)

print("Records with NA values three months previous:")
print(na_three_months_previous)
```
generate 12mo mvsums - for all agencies/month/year obs and across all crime types
```{r}
# Function to calculate 12-month cumulative sum 
mvs_12mo <- function(df) {
  df <- df %>%
    arrange(Year, Month) %>%
    group_by(`Agency Name`, State) %>%
    mutate(across(c(Murder, Burglary, Rape, Robbery, `Aggravated Assault`, `Motor Vehicle Theft`, Theft, `Violent Crime`, `Property Crime`), 
                  ~rollapply(.x, width = 12, FUN = sum, align = "right", fill = NA, partial = TRUE),
                  .names = "{col}_mvs_12mo")) %>%
    ungroup()
  return(df)
}

# Apply the function to the single dataframe
df_mvs_12mo1 <- mvs_12mo(cdf2)

# Print the result to verify
head(df_mvs_12mo1)
```
drop 2017
```{r}
df_mvs_12mo1 <- df_mvs_12mo1 %>% filter(Year != 2017)
```
make a new date field 
```{r}
df_mvs_12mo1 <- df_mvs_12mo1 %>% mutate(city_state = paste(`Agency Name`, State, sep = ", "))
# city state unique id
length(unique(df_mvs_12mo1$city_state))
# duplicate agency names
length(unique(df_mvs_12mo1$`Agency Name`))
```
add the reference file for links and the result
```{r}
#name of file to merge: OUTPUT_Participating Agencies Reference File
# Read the reference file and the wide dataset
ref_df <- read.csv("C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\_Ben and Jeff work\\Ben and Jeff working files\\OUTPUT_Participating Agencies Reference File.csv")

# cleave off that silliness
ref_df <- ref_df %>% mutate(city_state = paste(Agency.Name, state, sep = ", "))

head(ref_df)
#of obs in sample 27,373
```
join ref to sample
```{r}
df_w_ref <- df_mvs_12mo1 %>%
  left_join(ref_df, by = "city_state")

#of obs 27,373!
```
write it out!
```{r}
# Specify the folder path
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data"

# Create the full file path
file_path <- file.path(folder_path, "rtci_benjeff_sample.csv")

# Write the data frame to a .csv file
write.csv(df_w_ref, file = file_path, row.names = FALSE)

# Write the data frame to the data folder in Github repo
write.csv(df_w_ref, "data/rtci_benjeff_sample.csv")
```









calculate and add state counts
```{r}
state_counts <- cdf1 %>%
  group_by(Year, Month, State) %>%
  summarise(
    Murder= sum(Murder, na.rm = TRUE),
    Rape= sum(Rape, na.rm = TRUE),
    Robbery= sum(Robbery, na.rm = TRUE),
    `Aggravated Assault`= sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary= sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    .groups = 'drop'
  )

state_counts$`Agency Name` <- "All Agencies"

#join state counts with agency names to sample
cdf3 <- bind_rows(cdf1, state_counts)
head(cdf3)
```
quick jeff ask
```{r}
#his_2022 <- nationwide_counts %>% filter(Year ==2022)

folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data"

# Create the full file path
file_path <- file.path(folder_path, "agency_list_080624.csv")

# Write the data frame to a .csv file
write.csv(df1, file = file_path, row.names = FALSE)
```




find all months with 0 larcenies
```{r}
theft_zero <- df_mvs_12mo %>%
  filter(Theft == 0)

##some non-reportes from OH and MA expected
##tracy,ca; beaverton, or the review
```





AUDITING
```{r}
get_column_names_and_formats <- function(df_list) {
  # Extract column names and formats from each data frame
  column_list <- lapply(df_list, function(df) {
    colnames <- colnames(df)
    formats <- sapply(df, class)
    data.frame(ColumnName = colnames, Format = formats, stringsAsFactors = FALSE)
  })
  
  # Combine the column name and format information into a single data frame
  col_df <- do.call(rbind, lapply(seq_along(column_list), function(i) {
    df <- column_list[[i]]
    df$DataFrame <- names(df_list)[i]
    df
  }))
  
  return(col_df)
}

# Function to identify rarely used columns
identify_rare_columns <- function(col_df, threshold = 1) {
  # Count the frequency of each column name
  col_count <- col_df %>%
    group_by(ColumnName) %>%
    summarize(Frequency = n()) %>%
    arrange(Frequency)
  
  # Identify columns used in fewer data frames than the threshold
  rare_columns <- col_count %>%
    filter(Frequency <= threshold)
  
  return(rare_columns)
}

```



```{r}
# Get column names from each data frame
col_df <- get_column_names_and_formats(ldf2)

# Print the breakdown of column names
print(col_df)
```
```{r}
# Identify rarely used columns (e.g., used in 1 or fewer data frames)
rare_columns <- identify_rare_columns(col_df, threshold = 1)

# Print the rarely used columns
print(rare_columns)
```

duplicates?
```{r}
# Function to find unique values for "Agency Name" in a dataframe
get_unique_agencies <- function(df) {
  unique(df$`Agency Name`)
}

# Find unique values for "Agency Name" in all dataframes
unique_agencies_list <- lapply(ldf3, get_unique_agencies)

# Combine all unique values into a single vector
all_unique_agencies <- unlist(unique_agencies_list)

# Find duplicate agency names across all dataframes
duplicate_agencies <- all_unique_agencies[duplicated(all_unique_agencies)]

# View the unique agency names
print("Unique Agency Names Across All Dataframes")
print(unique(all_unique_agencies))

# View the duplicate agency names
print("Duplicate Agency Names Across All Dataframes")
print(duplicate_agencies)
```
what are we kicking when we rowbind?
```{r}
# Function to extract unique values from 'Agency.Name' column in each dataframe
extract_unique_agencies <- function(df_list, column_name) {
  unique_values <- df_list %>%
    map(~ .x %>% pull(.data[[column_name]])) %>%
    unlist() %>%
    unique()
  
  return(unique_values)
}

# Extract unique 'Agency.Name' values from the list of dataframes
unique_agencies <- extract_unique_agencies(ldf3, "Agency Name")

# Create a dataframe with these unique values
df1 <- as.data.frame(unique(unique_agencies))


# Count occurrences of values in the 'name' column for both dataframes
counts_df1 <- as.data.frame(table(df1$name))
counts_df2 <- as.data.frame(table(df2$name))

# Rename columns for clarity
colnames(counts_df1) <- c("name", "count_df1")
colnames(counts_df2) <- c("name", "count_df2")

# Merge the two count dataframes by the 'name' column
comparison <- merge(counts_df1, counts_df2, by = "name", all = TRUE)

# Replace NA values with 0 (if a name is not found in one of the dataframes)
comparison[is.na(comparison)] <- 0

# View the comparison
print("Comparison of Value Counts in 'name' Column Across Two Dataframes")
print(comparison)


# Function to extract unique values from a column and save as a vector
extract_unique_values <- function(df, column_name) {
  unique_values <- df %>% pull(.data[[column_name]]) %>% unique()
  return(unique_values)
}

# Extract unique values from 'Agency.Name' column in both dataframes
unique_values_df1 <- extract_unique_values(df1, "Agency.Name")
unique_values_df2 <- extract_unique_values(combined_df, "Agency Name")

# Compare the unique values between the two vectors
only_in_df1 <- setdiff(unique_values_df1, unique_values_df2)
only_in_df2 <- setdiff(unique_values_df2, unique_values_df1)
in_both <- intersect(unique_values_df1, unique_values_df2)

# Print the comparison results
cat("Unique values only in df1:\n")
print(only_in_df1)
cat("\nUnique values only in df2:\n")
print(only_in_df2)
cat("\nUnique values in both df1 and df2:\n")
print(in_both)

```
