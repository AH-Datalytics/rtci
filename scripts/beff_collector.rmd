---
title: "ben/jeff collector"
output: github_document
started: "07-23-2024"
---
read in the data from the ben/jeff folder
```{r}
library(tidyverse)
library(dplyr)
library(readr)
library(stringr)
library(zoo)
```
directory path where the arizona files are stored
```{r}
data_dir <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\_Ben and Jeff work"

file_paths <- list.files(data_dir, pattern = "\\.csv$", full.names = TRUE)

crime_types <- c("Agency Name",
                 "Murder", "Rape", "Robbery",
                 "Aggravated Assault", "Burglary", 
                 "Theft", "Motor Vehicle Theft", 
                 "Month", "Year")
```
describe all the csv's coming in
```{r}
# Function to get information about each CSV file
get_csv_info <- function(file) {
  df <- read_csv(file)
  data.frame(
    file_name = basename(file),
    num_columns = ncol(df),
    column_names = paste(names(df), collapse = ", "),
    column_formats = paste(sapply(df, class), collapse = ", ")
  )
}

# Apply the function to each CSV file and combine the results into a single dataframe
csv_info_df <- map_df(file_paths, get_csv_info)

head(csv_info_df)
```
read everything in, extract the month/year and do the initial processing
```{r}
# Function to read all CSV files in a folder and save them as data frames in a list
read_csvs <- function(folder_path) {
  # List all CSV files in the directory
  file_paths <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)
  
  # Debug: Check if any files are listed
  if (length(file_paths) == 0) {
    stop("No CSV files found in the specified directory.")
  } else {
    message("Processing ", length(file_paths), " files.")
  }
  
  # Function to read a single CSV file
  read_csv_file <- function(file_path) {
    # Debug: Check the file path
    message("Reading file: ", file_path)
    
    # Attempt to read the CSV file
    tryCatch({
      df <- read_csv(file_path, show_col_types = FALSE)
      return(df)
    }, error = function(e) {
      warning("Failed to read: ", file_path, " Error: ", e$message)
      return(NULL)  # Return NULL if the file cannot be read
    })
  }
  
  # Read all CSV files and save them as data frames in a list
  df_list <- lapply(file_paths, read_csv_file)
  
  # Name each element in the list with the corresponding file name (without extension)
  names(df_list) <- tools::file_path_sans_ext(basename(file_paths))
  
  return(df_list)
}

ldf <- read_csvs(data_dir)

# Print the names of the data frames in the list to verify
print(names(ldf))

head(ldf[1])
```
let's get the unique number of agencies at the beginning
```{r}
# Function to get the count of unique 'Agency Name'
get_unique_agency_count <- function(df) {
  length(unique(df$`Agency Name`))
}

# Apply the function to each dataframe in the list and store the results
unique_agency_counts <- map(ldf, get_unique_agency_count)

total_agency_raw <- sum(unlist(unique_agency_counts))

# Print the results
head(total_agency_raw)
##332 as of this writing this and counting...why do we lose agencies at the end?
```

format everything
```{r}
# Define the format_cols function
format_cols <- function(df) {
  # Remove the Arson column
  df <- df[, !(names(df) %in% "Arson")]
  
  # Convert specified columns to character
  char_cols <- c("Agency Name", "State")
  for (col in char_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.character(df[[col]])
    }
  }
  
  # Convert specified columns to numeric
  num_cols <- c("Murder", "Rape", "Robbery", "Aggravated Assault", "Burglary", 
                "Theft", "Motor Vehicle Theft", "Month", "Year")
  for (col in num_cols) {
    if (col %in% names(df)) {
      df[[col]] <- as.numeric(df[[col]])
    }
  }
  
  return(df)
}

ldf1 <- lapply(ldf, format_cols)
head(ldf1[1])
```
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts1 <- map(ldf1, get_unique_agency_count)

total_agency_raw1 <- sum(unlist(unique_agency_counts1))

# Print the results
head(total_agency_raw1)
##332 as of this writing this and counting...why do we lose agencies at the end?
```
next...
```{r}
# Ensure all data frames have the same columns and column types
all_columns <- Reduce(union, lapply(ldf1, names))

# Function to ensure all data frames have the same columns
standardize_columns <- function(df, all_columns) {
  missing_cols <- setdiff(all_columns, names(df))
  for (col in missing_cols) {
    df[[col]] <- NA
  }
  return(df[all_columns])
}

# Apply the standardize_columns function to each dataframe in the list
ldf2 <- lapply(ldf1, standardize_columns, all_columns = all_columns)

#change column names where they don't match - larceny to theft
rename_larceny_to_theft <- function(df) {
  if ("Larceny" %in% names(df)) {
    names(df)[names(df) == "Larceny"] <- "Theft"
  }
  return(df)
}

ldf2 <- lapply(ldf2, rename_larceny_to_theft)
head(ldf2[1])
```
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts2 <- map(ldf2, get_unique_agency_count)

total_agency_raw2 <- sum(unlist(unique_agency_counts2))

# Print the results
head(total_agency_raw2)
##332 as of this writing this and counting...why do we lose agencies at the end?
```

still have a few odd column names
```{r}
acceptable_names <- c("Agency Name", "Murder", "Rape", "Robbery", "Aggravated Assault", 
"Burglary", "Theft", "Motor Vehicle Theft", "Year", "Month", "State")

ldf3 <- lapply(ldf2, function(df) {
  df[, (names(df) %in% acceptable_names)]
})

head(ldf3[1])
```
```{r}
# Apply the function to each dataframe in the list and store the results
unique_agency_counts3 <- map(ldf3, get_unique_agency_count)

total_agency_raw3 <- sum(unlist(unique_agency_counts3))

# Print the results
head(total_agency_raw3)
##332 as of this writing this and counting...why do we lose agencies at the end?
```
combine and check it out
```{r}
combined_df <- do.call(rbind, ldf3)

rownames(combined_df) <- NULL

#select out acceptable columns and take a look just to make sure
combined_df <- combined_df %>% select(acceptable_names)
head(combined_df)
```
```{r}
length(unique(combined_df$`Agency Name`))
```
remove non-current jurisdictions
```{r}
crime_types <- c("Murder", "Rape", "Robbery",
                 "Aggravated Assault", "Burglary", 
                 "Theft", "Motor Vehicle Theft")

 # Create a Date column from Month and Year columns
  df <- combined_df %>%
         mutate(Date = as.Date(paste(Year, Month, "01", sep = "-")))

# Function to remove current and previous months and...
#check for valid numerical counts in the obs two months prior
#check_valid_counts <- function(df, crime_types, date_column) {
  # Get the current month and year
  current_month <- month(Sys.Date())
  current_year <- year(Sys.Date())
  
  # Get the previous month and year
  if (current_month == 1) {
    previous_month <- 12
    previous_year <- current_year - 1
    two_months_prior_month <- 11
    two_months_prior_year <- current_year - 1
  } else if (current_month == 2) {
    previous_month <- 1
    previous_year <- current_year
    two_months_prior_month <- 12
    two_months_prior_year <- current_year - 1
  } else {
    previous_month <- current_month - 1
    previous_year <- current_year
    two_months_prior_month <- current_month - 2
    two_months_prior_year <- current_year
  }
  
  # Filter rows for the current and previous month/year
  combined_df <- df %>%
    filter((year(Date)) == current_year & month(Date) == current_month |
           (year(Date)) == previous_year & month(Date) == previous_month
    )
# Filter rows for two months prior
two_months_prior_data <- df %>%
    filter(year(Date) == two_months_prior_year & month(Date) == two_months_prior_month)
  
# Check out two months previous - the first month of our sample
invalid_two_months_prior <- two_months_prior_data %>%
  filter(if_any(c(Murder, `Motor Vehicle Theft`, `Aggravated Assault`,
                  Burglary, Robbery, Theft, Rape), ~ is.na(.))) %>%
  pull(`Agency Name`) %>%
  unique()

# Save the invalid records as a separate vector
invalid_records <- two_months_prior_data %>%
  filter(if_any(c(Murder, `Motor Vehicle Theft`, `Aggravated Assault`,
                  Burglary, Robbery, Theft, Rape), ~ is.na(.)))

head(invalid_records)
```
drop everything from current year/month and current year/previous month
```{r}
# Filter out observations with the current month and year or previous month and year
cdf <- combined_df %>%
  filter(
    !(Year == current_year & Month == current_month) |
    !(Year == current_year & Month == previous_month)
  )

# Print the result
head(cdf)

```
calculate and add nationwide counts
```{r}
nationwide_counts <- cdf %>%
  group_by(Year, Month) %>%
  summarise(
    Murder= sum(Murder, na.rm = TRUE),
    Rape= sum(Rape, na.rm = TRUE),
    Robbery= sum(Robbery, na.rm = TRUE),
    `Aggravated Assault`= sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary= sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    .groups = 'drop'
  )

# Display the aggregate level dataframe
head(nationwide_counts)
```
add the nationwide counts to the sample once it's working
```{r}
nationwide_counts$`Agency Name` <- "Nationwide Count"

cdf1 <- bind_rows(cdf, nationwide_counts)
head(cdf1)
```
calculate and add state counts
```{r}
state_counts <- cdf %>%
  group_by(Year, Month, State) %>%
  summarise(
    Murder= sum(Murder, na.rm = TRUE),
    Rape= sum(Rape, na.rm = TRUE),
    Robbery= sum(Robbery, na.rm = TRUE),
    `Aggravated Assault`= sum(`Aggravated Assault`, na.rm = TRUE),
    Burglary= sum(Burglary, na.rm = TRUE),
    Theft = sum(Theft, na.rm = TRUE),
    `Motor Vehicle Theft` = sum(`Motor Vehicle Theft`, na.rm = TRUE),
    .groups = 'drop'
  )

# Display the aggregate level dataframe
head(state_counts)
```
vc/pc groupings
```{r}
# Add new columns for violent and property crime
cdf_groups <- cdf %>%
  mutate(
    vio_crime = Murder + Rape + Robbery + `Aggravated Assault`,
    prop_crime = Burglary + Theft + `Motor Vehicle Theft`
  )
```


```{r}
# Function to calculate 12-month cumulative sum 
mvs_12mo <- function(df) {
  df <- df %>%
    arrange(Year, Month) %>%
    group_by(`Agency Name`, State) %>%
    mutate(across(c(Murder, Burglary, Rape, Robbery, `Aggravated Assault`, `Motor Vehicle Theft`, Theft), 
                  ~rollapply(.x, width = 12, FUN = sum, align = "right", fill = NA, partial = TRUE),
                  .names = "{col}_mvs_12mo")) %>%
    ungroup()
  return(df)
}

# Apply the function to the single dataframe
df_mvs_12mo1 <- mvs_12mo(cdf1)

# Print the result to verify
head(df_mvs_12mo1)
```
agency number!!?
```{r}
length(unique(combined_df$`Agency Name`))
```
drop 2017
```{r}
df_mvs_12mo <- df_mvs_12mo %>% filter(Year != 2017)
```
find all months with 0 larcenies
```{r}
theft_zero <- df_mvs_12mo %>%
  filter(Theft == 0)

##some non-reportes from OH and MA expected
##tracy,ca; beaverton, or the review
```
drop most recent month
```{r}

```
add the reference file for links and the result
```{r}
#name of file to merge: OUTPUT_Participating Agencies Reference File
# Read the reference file and the wide dataset
reference_data <- read.csv("OUTPUT_Participating Agencies Reference File.csv")
wide_data <- read.csv("wide_dataset.csv")

# Inspect the first few rows of each dataset to ensure the column names and structures are as expected
head(reference_data)
head(wide_data)

# Merge the datasets on city and state columns
merged_data <- wide_data %>%
  left_join(reference_data, by = c("city", "state"))


```
write it out!
```{r}
# Specify the folder path
folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data"

# Create the full file path
file_path <- file.path(folder_path, "rtci_benjeff_sample.csv")

# Write the data frame to a .csv file
write.csv(df_mvs_12mo, file = file_path, row.names = FALSE)

# Write the data frame to the data folder in Github repo
write.csv(df_mvs_12mo, "data/rtci_benjeff_sample.csv")
```

1 -add % change to mvs for groupings -sum
1a -august pull - round off and remove sys month - august and previous month 
##august - 8/1 we get June data
2 -reference file inclusion - pop, groupings, ORI, city/state
3 -make spatial data
4 -create vc/pc groupings - The descending order of UCR violent crimes
 are murder and nonnegligent manslaughter, rape, robbery, and aggravated assault, 
 followed by the property crimes of burglary, larceny-theft, and motor vehicle theft.
5 -run wheeler script again and report agency issues
6 -map process w/ OB
7 -links to sources
8 -ytd table for each agency in the sample
9 -based on 2022 we think we are capturing X amount of the total crimes that 
10 -0 larceny agencies in a month find
11 -nationwide is being summed based on who is and isn'tincluded based on our limits and something

august 1st - collect data for June

audit 
-pull out agencies 

quick jeff ask
```{r}
his_2022 <- nationwide_counts %>% filter(Year ==2022)

folder_path <- "C:\\OneDrive\\OneDrive - ahdatalytics.com\\Clients\\Real Time Crime Index\\Open Source Data\\Collected Sample Data"

# Create the full file path
file_path <- file.path(folder_path, "nationwide_sample_2022.csv")

# Write the data frame to a .csv file
write.csv(his_2022, file = file_path, row.names = FALSE)
```









AUDITING
```{r}
get_column_names_and_formats <- function(df_list) {
  # Extract column names and formats from each data frame
  column_list <- lapply(df_list, function(df) {
    colnames <- colnames(df)
    formats <- sapply(df, class)
    data.frame(ColumnName = colnames, Format = formats, stringsAsFactors = FALSE)
  })
  
  # Combine the column name and format information into a single data frame
  col_df <- do.call(rbind, lapply(seq_along(column_list), function(i) {
    df <- column_list[[i]]
    df$DataFrame <- names(df_list)[i]
    df
  }))
  
  return(col_df)
}

# Function to identify rarely used columns
identify_rare_columns <- function(col_df, threshold = 1) {
  # Count the frequency of each column name
  col_count <- col_df %>%
    group_by(ColumnName) %>%
    summarize(Frequency = n()) %>%
    arrange(Frequency)
  
  # Identify columns used in fewer data frames than the threshold
  rare_columns <- col_count %>%
    filter(Frequency <= threshold)
  
  return(rare_columns)
}

```



```{r}
# Get column names from each data frame
col_df <- get_column_names_and_formats(ldf2)

# Print the breakdown of column names
print(col_df)
```
```{r}
# Identify rarely used columns (e.g., used in 1 or fewer data frames)
rare_columns <- identify_rare_columns(col_df, threshold = 1)

# Print the rarely used columns
print(rare_columns)
```

duplicates?
```{r}
# Function to find unique values for "Agency Name" in a dataframe
get_unique_agencies <- function(df) {
  unique(df$`Agency Name`)
}

# Find unique values for "Agency Name" in all dataframes
unique_agencies_list <- lapply(ldf3, get_unique_agencies)

# Combine all unique values into a single vector
all_unique_agencies <- unlist(unique_agencies_list)

# Find duplicate agency names across all dataframes
duplicate_agencies <- all_unique_agencies[duplicated(all_unique_agencies)]

# View the unique agency names
print("Unique Agency Names Across All Dataframes")
print(unique(all_unique_agencies))

# View the duplicate agency names
print("Duplicate Agency Names Across All Dataframes")
print(duplicate_agencies)
```
what are we kicking when we rowbind?
```{r}
# Function to extract unique values from 'Agency.Name' column in each dataframe
extract_unique_agencies <- function(df_list, column_name) {
  unique_values <- df_list %>%
    map(~ .x %>% pull(.data[[column_name]])) %>%
    unlist() %>%
    unique()
  
  return(unique_values)
}

# Extract unique 'Agency.Name' values from the list of dataframes
unique_agencies <- extract_unique_agencies(ldf3, "Agency Name")

# Create a dataframe with these unique values
df1 <- as.data.frame(unique(unique_agencies))


# Count occurrences of values in the 'name' column for both dataframes
counts_df1 <- as.data.frame(table(df1$name))
counts_df2 <- as.data.frame(table(df2$name))

# Rename columns for clarity
colnames(counts_df1) <- c("name", "count_df1")
colnames(counts_df2) <- c("name", "count_df2")

# Merge the two count dataframes by the 'name' column
comparison <- merge(counts_df1, counts_df2, by = "name", all = TRUE)

# Replace NA values with 0 (if a name is not found in one of the dataframes)
comparison[is.na(comparison)] <- 0

# View the comparison
print("Comparison of Value Counts in 'name' Column Across Two Dataframes")
print(comparison)


# Function to extract unique values from a column and save as a vector
extract_unique_values <- function(df, column_name) {
  unique_values <- df %>% pull(.data[[column_name]]) %>% unique()
  return(unique_values)
}

# Extract unique values from 'Agency.Name' column in both dataframes
unique_values_df1 <- extract_unique_values(df1, "Agency.Name")
unique_values_df2 <- extract_unique_values(combined_df, "Agency Name")

# Compare the unique values between the two vectors
only_in_df1 <- setdiff(unique_values_df1, unique_values_df2)
only_in_df2 <- setdiff(unique_values_df2, unique_values_df1)
in_both <- intersect(unique_values_df1, unique_values_df2)

# Print the comparison results
cat("Unique values only in df1:\n")
print(only_in_df1)
cat("\nUnique values only in df2:\n")
print(only_in_df2)
cat("\nUnique values in both df1 and df2:\n")
print(in_both)

```